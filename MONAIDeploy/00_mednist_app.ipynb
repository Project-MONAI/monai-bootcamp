{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1972af8a-0243-43ef-8894-766117edffbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "![MONAI Logo](monai.png)\n",
    "\n",
    "# Deploying a MedNIST Classifier App with MONAI Deploy App SDK (Prebuilt Model)\n",
    "\n",
    "This tutorial demos the process of packaging a trained model using MONAI Deploy App SDK into an artifact that can be run as a local application that performs inference, a workflow job doing the same, and a Docker containerized workflow execution.\n",
    "\n",
    "## Implementing and Packaging Application with MONAI Deploy App SDK\n",
    "\n",
    "Based on the Torchscript model(`classifier.zip`), we will implement an application that processes an input Jpeg image and write the prediction(classification) result as a JSON file(`output.json`).\n",
    "\n",
    "In our inference application, we will define two operators:\n",
    "\n",
    "1. `LoadPILOperator` - Load a JPEG image from the input path and pass the loaded image object to the next operator.\n",
    "    - This Operator does similar job with `LoadImage(image_only=True)` transform in *train_transforms*, but handles only one image.\n",
    "    - **Input**: a file path ([`DataPath`](/modules/_autosummary/monai.deploy.core.domain.DataPath))\n",
    "    - **Output**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "2. `MedNISTClassifierOperator` - Pre-transform the given image by using MONAI's `Compose` class, feed to the Torchscript model (`classifier.zip`), and write the prediction into a JSON file(`output.json`)\n",
    "    - Pre-transforms consist of three transforms -- `AddChannel`, `ScaleIntensity`, and `EnsureType`.\n",
    "    - **Input**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Output**: a folder path that the prediction result(`output.json`) would be written ([`DataPath`](/modules/_autosummary/monai.deploy.core.domain.DataPath))\n",
    "\n",
    "The workflow of the application would look like this.\n",
    "\n",
    "<img src=\"images/mednist_workflow.png\" alt=\"Workflow\" style=\"width: 600px;margin-left:auto;margin-right:auto;\"/>\n",
    "\n",
    "### Contents\n",
    "* [Setup](#setup)\n",
    "* [Creating Operator Class](#create_op)\n",
    "* [Creating Application Class](#create_app)\n",
    "* [Executing App Locally](#execute_app_local)\n",
    "* [Conclusion](#conclusion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44872db8-5a19-4e3f-89fa-d18ebbf471b2",
   "metadata": {},
   "source": [
    "### Using Google Colab\n",
    "\n",
    "This notebook has the pip command for installing MONAI and will be added to any subsequent notebook.\n",
    "\n",
    "**Enabling GPU Support**\n",
    "\n",
    "To use GPU resources through Colab, change the runtime to GPU:\n",
    "\n",
    "1. From the **\"Runtime\"** menu select **\"Change Runtime Type\"**\n",
    "2. Choose **\"GPU\"** from the drop-down menu\n",
    "3. Click **\"SAVE\"**\n",
    "\n",
    "This will reset the notebook and probably ask you if you are a robot (these instructions assume you are not)\n",
    "\n",
    "### Verify GPU Access\n",
    "\n",
    "Running **!nvidia-smi** in a cell will verify this has worked and show you what kind of hardware you have access to.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ab936-036a-4907-a783-090dec5d8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary image loading/processing packages for the application\n",
    "!pip install -q \"Pillow\"\n",
    "!pip install -q \"scikit-image\"\n",
    "!pip install -q \"wget\"\n",
    "!pip install -q \"pydicom\"\n",
    "!pip install -q \"highdicom\"\n",
    "!pip install -q \"matplotlib\"\n",
    "!pip install -q \"typeguard==2.12.1\"\n",
    "%matplotlib inline\n",
    "\n",
    "# Install MONAI Deploy App SDK package\n",
    "!pip install -qU \"monai-deploy-app-sdk\"\n",
    "!pip install -qU \"monai[ignite, nibabel, torchvision, tqdm]==1.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ce320-fa7a-4386-a8fc-cbe6e4d687d5",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "\n",
    "To begin, check that the NVIDIA driver has been installed correctly. The `nvidia-smi` command should run and output information about the GPUs on your system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e739a2-844f-42da-ac51-de67b2d2c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44529e70-73d7-4cd8-aff9-0266af27f65a",
   "metadata": {},
   "source": [
    "### 1.1 Setup environment\n",
    "\n",
    "We'll set up folder called notebook_0 where we'll extract our data, models, and write out output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e44d52-157f-4994-a7f0-e507028bbf32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_ROOT=\"notebook_0/\"\n",
    "!mkdir -p notebook_0\n",
    "!gdown \"https://drive.google.com/uc?id=1yJ4P-xMNEfN6lIOq_u6x1eMAq1_MJu-E\"\n",
    "!unzip -o mednist_classifier_data.zip -d notebook_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89429299-335e-4e95-a63c-2a17c556b9b9",
   "metadata": {},
   "source": [
    "### 1.2 Setup imports\n",
    "\n",
    "Let's import necessary classes/decorators and define `MEDNIST_CLASSES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf99adf-d6de-4ae4-8713-98945c9a27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai.deploy.core as md\n",
    "from monai.deploy.core import (\n",
    "    Application,\n",
    "    DataPath,\n",
    "    ExecutionContext,\n",
    "    Image,\n",
    "    InputContext,\n",
    "    IOType,\n",
    "    Operator,\n",
    "    OutputContext,\n",
    ")\n",
    "from monai.transforms import AddChannel, Compose, EnsureType, ScaleIntensity\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]\n",
    "\n",
    "from monai.deploy.operators.dicom_text_sr_writer_operator import DICOMTextSRWriterOperator, EquipmentInfo, ModelInfo\n",
    "from typing import Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c5c81-6f3d-4ae0-9ea3-9df674240d81",
   "metadata": {},
   "source": [
    "<a id='create_op'></a>\n",
    "## 2. Creating Operator classes\n",
    "\n",
    "### 2.1 LoadPIL Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afef8f-2928-470d-b3f8-1902623bd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@md.input(\"image\", DataPath, IOType.DISK)\n",
    "@md.output(\"image\", Image, IOType.IN_MEMORY)\n",
    "@md.env(pip_packages=[\"pillow\"])\n",
    "class LoadPILOperator(Operator):\n",
    "    \"\"\"Load image from the given input (DataPath) and set numpy array to the output (Image).\"\"\"\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "\n",
    "        input_path = op_input.get().path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image = PILImage.open(input_path)\n",
    "        image = image.convert(\"L\")  # convert to greyscale image\n",
    "        image_arr = np.asarray(image)\n",
    "\n",
    "        output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
    "        op_output.set(output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5199895a-bd15-4c76-87c3-fa37b2cb8757",
   "metadata": {},
   "source": [
    "### 1.2 MedNIST Classifier Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb36651-b7a0-4c43-9393-f52bd9dd3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "@md.input(\"image\", Image, IOType.IN_MEMORY)\n",
    "@md.output(\"output\", DataPath, IOType.DISK)\n",
    "@md.output(\"result_text\", Text, IOType.IN_MEMORY)\n",
    "@md.env(pip_packages=[\"monai\"])\n",
    "class MedNISTClassifierOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return Compose([AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "\n",
    "        img = op_input.get().asnumpy()  # (64, 64), uint8\n",
    "        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n",
    "        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        model = context.models.get()  # get a TorchScriptModel object\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        result = MEDNIST_CLASSES[output_classes[0]]  # get the class name\n",
    "        print(result)\n",
    "        op_output.set(result, \"result_text\")\n",
    "\n",
    "        ##### Get output (folder) path and create the folder if not exists\n",
    "        # output_folder = op_output.get().path\n",
    "        # output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        ### The following gets the App context's output path, instead the operator's.\n",
    "        output_folder = context.output.get().path\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        \n",
    "        # Write result to \"output.json\"\n",
    "        output_path = output_folder / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494efbe-19f7-46c9-b03c-31d06dc8b79d",
   "metadata": {},
   "source": [
    "<a id='create_app'></a>\n",
    "## 2. Creating Application class\n",
    "\n",
    "Our application class would look like below.\n",
    "\n",
    "It defines `App` class inheriting `Application` class.\n",
    "\n",
    "`LoadPILOperator` is connected to `MedNISTClassifierOperator` by using `self.add_flow()` in `compose()` method of `App`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dece25-1206-466b-bfae-e18f1ab18e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@md.resource(cpu=1, gpu=1, memory=\"1Gi\")\n",
    "class App(Application):\n",
    "    \"\"\"Application class for the MedNIST classifier.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        load_pil_op = LoadPILOperator()\n",
    "        classifier_op = MedNISTClassifierOperator()\n",
    "\n",
    "        self.add_flow(load_pil_op, classifier_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7031e-1d94-4e61-be25-4697c98e3020",
   "metadata": {},
   "source": [
    "<a id='execute_app_local'></a>\n",
    "## 3. Executing app locally\n",
    "\n",
    "We can execute the app in the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2315e-4ff4-499c-bd4e-72759ca8a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = App()\n",
    "app.run(input=NOTEBOOK_ROOT+\"/input/AbdomenCT_007000.jpeg\", output=NOTEBOOK_ROOT+\"/output\", model=NOTEBOOK_ROOT+\"classifier.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f50fe-6186-453f-8f3b-7217ba30e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $NOTEBOOK_ROOT/output/output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14367171-b05f-4fba-a679-357fe295fc67",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we have walked through the process to create a classification task using a pre-built model using MONAI Deploy App SDK and running the application in Jupyter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
