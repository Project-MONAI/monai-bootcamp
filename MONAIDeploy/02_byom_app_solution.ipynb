{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MONAI Logo](monai.png)\n",
    "\n",
    "# MONAI Deploy App SDK - BYOM Application\n",
    "\n",
    "This tutorial you'll walk through creating your own MONAI Application Package (MAP) with a custom model.  We'll provide some boilerplate code and you'll do the rest!\n",
    "\n",
    "### Table of Contents\n",
    "* [Setup](#1.-Setup)\n",
    "* [Create Operator Class](#2.-Create-Operator-Class)\n",
    "* [Create Application Class](#3.-Create-Application-Class)\n",
    "* [Excuting App Locally](#4.-Executing-app-locally)\n",
    "* [Conclusion](#5.-Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Google Colab\n",
    "\n",
    "This notebook has the pip command for installing MONAI and will be added to any subsequent notebook.\n",
    "\n",
    "**Enabling GPU Support**\n",
    "\n",
    "To use GPU resources through Colab, change the runtime to GPU:\n",
    "\n",
    "1. From the **\"Runtime\"** menu select **\"Change Runtime Type\"**\n",
    "2. Choose **\"GPU\"** from the drop-down menu\n",
    "3. Click **\"SAVE\"**\n",
    "\n",
    "This will reset the notebook and probably ask you if you are a robot (these instructions assume you are not)\n",
    "\n",
    "### Verify GPU Access\n",
    "\n",
    "Running **!nvidia-smi** in a cell will verify this has worked and show you what kind of hardware you have access to.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary image loading/processing packages for the application\n",
    "!pip install -q \"Pillow\"\n",
    "!pip install -q \"scikit-image\"\n",
    "!pip install -q \"wget\"\n",
    "!pip install -q \"pydicom\"\n",
    "!pip install -q \"highdicom\"\n",
    "!pip install -q \"matplotlib\"\n",
    "!pip install -q \"typeguard==2.12.1\"\n",
    "%matplotlib inline\n",
    "\n",
    "# Install MONAI Deploy App SDK package\n",
    "!pip install -qU \"monai-deploy-app-sdk\"\n",
    "!pip install -qU \"monai[ignite, nibabel, torchvision, tqdm, fire]==1.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "\n",
    "To begin, check that the NVIDIA driver has been installed correctly. The `nvidia-smi` command should run and output information about the GPUs on your system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Setup Environment\n",
    "\n",
    "We'll set up folder called notebook_2 where we'll extract our data, models, and write out output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_ROOT=\"notebook_2/\"\n",
    "MODEL=\"pancreas_ct_dints_segmentation\"\n",
    "!mkdir -p {NOTEBOOK_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Setup\n",
    "\n",
    "Download/Extract ai_spleen_seg_data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ai_spleen_bundle_data test data zip file\n",
    "!gdown \"https://drive.google.com/uc?id=1Uds8mEvdGNYUuvFpTtCQ8gNU97bAPCaQ\"\n",
    "\n",
    "# After downloading ai_spleen_bundle_data zip file from the web browser or using gdown,\n",
    "!unzip -o \"ai_spleen_seg_bundle_data.zip\" -d \"notebook_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Download Model\n",
    "\n",
    "We're going to use the MONAI Bundle CLI to download a model from the [MONAI Model Zoo](https://monai.io/model-zoo).  For this notebook we're going to download the Pancreas CT DiNTS Segmentation Model and we're specifying version 0.3.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m monai.bundle download --name {MODEL}  --version \"0.3.6\" --bundle_dir {NOTEBOOK_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Setup imports\n",
    "\n",
    "Let's import necessary classes/decorators to define Application and Operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from os import path\n",
    "\n",
    "from numpy import uint8\n",
    "\n",
    "import monai.deploy.core as md\n",
    "from monai.deploy.core import ExecutionContext, Image, InputContext, IOType, Operator, OutputContext\n",
    "from monai.deploy.operators.monai_seg_inference_operator import InMemImageReader, MonaiSegInferenceOperator\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    ")\n",
    "\n",
    "# Required for setting SegmentDescription attributes. Direct import as this is not part of App SDK package.\n",
    "from pydicom.sr.codedict import codes\n",
    "\n",
    "from monai.deploy.core import Application, resource\n",
    "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
    "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator, SegmentDescription\n",
    "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
    "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
    "from monai.deploy.operators.clara_viz_operator import ClaraVizOperator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Operator Class\n",
    "\n",
    "You'll create the Pancreas Segmentation operator.  We've define the pre_process and post_process pipeline for you.\n",
    "\n",
    "#### 2.1 Exercise\n",
    "<div class=\"alert alert-block alert-info\"> Implement compute() method </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@md.input(\"image\", Image, IOType.IN_MEMORY)\n",
    "@md.output(\"seg_image\", Image, IOType.IN_MEMORY)\n",
    "class PancreasSegOperator(Operator):\n",
    "    \"\"\"Performs Pancreas and Pancreas Tumor segmentation with a 3D image converted from a DICOM CT series.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        super().__init__()\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "\n",
    "        input_image = op_input.get(\"image\")\n",
    "        if not input_image:\n",
    "            raise ValueError(\"Input image is not found.\")\n",
    "\n",
    "        output_path = context.output.get().path\n",
    "\n",
    "        # This operator gets an in-memory Image object, so a specialized ImageReader is needed.\n",
    "        _reader = InMemImageReader(input_image)\n",
    "        pre_transforms = self.pre_process(_reader)\n",
    "        post_transforms = self.post_process(pre_transforms, path.join(output_path, \"prediction_output\"))\n",
    "\n",
    "        # Delegates inference and saving output to the built-in operator.\n",
    "        infer_operator = MonaiSegInferenceOperator(\n",
    "            (\n",
    "                96,\n",
    "                96,\n",
    "                96,\n",
    "            ),\n",
    "            pre_transforms,\n",
    "            post_transforms,\n",
    "        )\n",
    "\n",
    "        # Setting the keys used in the dictironary based transforms may change.\n",
    "        infer_operator.input_dataset_key = self._input_dataset_key\n",
    "        infer_operator.pred_dataset_key = self._pred_dataset_key\n",
    "\n",
    "        # Now let the built-in operator handles the work with the I/O spec and execution context.\n",
    "        infer_operator.compute(op_input, op_output, context)\n",
    "\n",
    "\n",
    "    def pre_process(self, img_reader) -> Compose:\n",
    "        \"\"\"Composes transforms for preprocessing input before predicting on a model.\"\"\"\n",
    "\n",
    "        my_key = self._input_dataset_key\n",
    "        return Compose(\n",
    "            [\n",
    "                LoadImaged(keys=my_key, reader=img_reader),\n",
    "                EnsureChannelFirstd(keys=my_key),\n",
    "                Orientationd(keys=my_key, axcodes=\"RAS\"),\n",
    "                Spacingd(keys=my_key, pixdim=[1.5, 1.5, 2.0], mode=[\"bilinear\"]),\n",
    "                ScaleIntensityRanged(keys=my_key, a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "                EnsureTyped(keys=my_key)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def post_process(self, pre_transforms: Compose, out_dir: str = \"./prediction_output\") -> Compose:\n",
    "        \"\"\"Composes transforms for postprocessing the prediction results.\"\"\"\n",
    "\n",
    "        pred_key = self._pred_dataset_key\n",
    "        return Compose(\n",
    "            [\n",
    "                Activationsd(keys=pred_key, softmax=True),\n",
    "                Invertd(keys=pred_key, transform=pre_transforms, orig_keys=self._input_dataset_key, nearest_interp=False),                \n",
    "                AsDiscreted(keys=pred_key, argmax=True),\n",
    "                SaveImaged(keys=pred_key, output_dir=out_dir, output_postfix=\"seg\", output_dtype=uint8),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Application Class\n",
    "\n",
    "You'll implement the Application class for your MONAI Deploy Application.  Remember to use the MONAI Deploy provided DICOM operators and instantiate your Inference Operator class from above.  You'll then need to create a DAG by linking the operators together.\n",
    "\n",
    "#### 3.1 Exercise\n",
    "<div class=\"alert alert-block alert-info\"> Implement compose() method </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@md.resource(cpu=1, gpu=1, memory=\"1Gi\")\n",
    "class AIPancreasTumorSegApp(Application):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Creates an application instance.\"\"\"\n",
    "\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def compose(self):\n",
    "        \"\"\"Creates the app specific operators and chain them up in the processing DAG.\"\"\"\n",
    "\n",
    "        self._logger.debug(f\"Begin {self.compose.__name__}\")\n",
    "        # Creates the custom operator(s) as well as SDK built-in operator(s).\n",
    "        study_loader_op = DICOMDataLoaderOperator()\n",
    "        series_selector_op = DICOMSeriesSelectorOperator(rules=Sample_Rules_Text)\n",
    "        series_to_vol_op = DICOMSeriesToVolumeOperator()\n",
    "        # Model specific inference operator, supporting MONAI transforms.\n",
    "\n",
    "        # Creates the model specific segmentation operator\n",
    "        pancreas_seg_op = PancreasSegOperator()\n",
    "\n",
    "        # Create DICOM Seg writer providing the required segment description for each segment with\n",
    "        # the actual algorithm and the pertinent organ/tissue.\n",
    "        # The segment_label, algorithm_name, and algorithm_version are limited to 64 chars.\n",
    "        # https://dicom.nema.org/medical/dicom/current/output/chtml/part05/sect_6.2.html\n",
    "        # User can Look up SNOMED CT codes at, e.g.\n",
    "        # https://bioportal.bioontology.org/ontologies/SNOMEDCT\n",
    "\n",
    "        _algorithm_name = \"3D segmentation of multi-Organs from a CT series\"\n",
    "        _algorithm_family = codes.DCM.ArtificialIntelligence\n",
    "        _algorithm_version = \"0.1.0\"\n",
    "\n",
    "        segment_descriptions = [\n",
    "            SegmentDescription(\n",
    "                segment_label=\"Multi\",\n",
    "                segmented_property_category=codes.SCT.Organ,\n",
    "                segmented_property_type=codes.SCT.Abdomen,                \n",
    "                algorithm_name=_algorithm_name,\n",
    "                algorithm_family=_algorithm_family,\n",
    "                algorithm_version=_algorithm_version,\n",
    "            ),\n",
    "        ]        \n",
    "        \n",
    "        dicom_seg_writer = DICOMSegmentationWriterOperator(segment_descriptions)\n",
    "\n",
    "        # Create the processing pipeline, by specifying the source and destination operators, and\n",
    "        # ensuring the output from the former matches the input of the latter, in both name and type.\n",
    "        self.add_flow(study_loader_op, series_selector_op, {\"dicom_study_list\": \"dicom_study_list\"})\n",
    "        self.add_flow(\n",
    "            series_selector_op, series_to_vol_op, {\"study_selected_series_list\": \"study_selected_series_list\"}\n",
    "        )\n",
    "        self.add_flow(series_to_vol_op, pancreas_seg_op, {\"image\": \"image\"})\n",
    "\n",
    "        # Note below the dicom_seg_writer requires two inputs, each coming from a source operator.\n",
    "        self.add_flow(\n",
    "            series_selector_op, dicom_seg_writer, {\"study_selected_series_list\": \"study_selected_series_list\"}\n",
    "        )\n",
    "        self.add_flow(pancreas_seg_op, dicom_seg_writer, {\"seg_image\": \"seg_image\"})\n",
    "\n",
    "        viz_op = ClaraVizOperator()\n",
    "        self.add_flow(series_to_vol_op, viz_op, {\"image\": \"image\"})\n",
    "        self.add_flow(pancreas_seg_op, viz_op, {\"seg_image\": \"seg_image\"})        \n",
    "        \n",
    "        self._logger.debug(f\"End {self.compose.__name__}\")\n",
    "\n",
    "# This is a sample series selection rule in JSON, simply selecting CT series.\n",
    "# If the study has more than 1 CT series, then all of them will be selected.\n",
    "# Please see more detail in DICOMSeriesSelectorOperator.\n",
    "# For list of string values, e.g. \"ImageType\": [\"PRIMARY\", \"ORIGINAL\"], it is a match if all elements\n",
    "# are all in the multi-value attribute of the DICOM series.\n",
    "Sample_Rules_Text = \"\"\"\n",
    "{\n",
    "    \"selections\": [\n",
    "        {\n",
    "            \"name\": \"CT Series\",\n",
    "            \"conditions\": {\n",
    "                \"StudyDescription\": \"(.*?)\",\n",
    "                \"Modality\": \"(?i)CT\",\n",
    "                \"SeriesDescription\": \"(.*?)\",\n",
    "                \"ImageType\": [\"PRIMARY\", \"ORIGINAL\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Executing app locally\n",
    "\n",
    "We can execute the app in the Jupyter notebook. Note that the DICOM files of the CT Abdomen series must be present in the `dcm` and the Torch Script model at `model.ts`. Please use the actual path in your environment.\n",
    "\n",
    "### 4.1 Exercise\n",
    "<div class=\"alert alert-block alert-info\"> You'll test your application locally before trying to package the application. We've provided the `Run` function and passed the correct parameters.  If you have different paths, please update before running.  All of the oeprators should pass and you should have a Clara Viz viewer open. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = AIPancreasTumorSegApp()\n",
    "\n",
    "app.run(input=NOTEBOOK_ROOT+\"/dcm\", output=NOTEBOOK_ROOT+\"/output\", model=NOTEBOOK_ROOT+MODEL+\"/models/model.ts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "In this notebook, you have implemented a MONAI Deploy Application and utilized a pretrained model from the MONAI Model Zoo.\n",
    "\n",
    "### 5.1 What's Next\n",
    "You're now ready to use MONAI Deploy on any current or future model you're working on!  Check out the [MONAI Deploy Github](https://github.com/Project-MONAI/monai-deploy) to keep up to date on the latest changes.  And feel free to report an issue, submit a pull request, contribute in discussions, or attending the MONAI Deploy Working Group meeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b4ab1155d0cd1042497eb40fd55b2d15caf4b3c0f9fbfcc7ba4404045d40f12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
