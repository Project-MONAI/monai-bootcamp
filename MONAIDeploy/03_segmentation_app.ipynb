{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"monai.png\" style=\"width: 700px;\"/>\n",
    "\n",
    "Welcome to the MONAI bootcamp! This tutorial shows how to create an organ segmentation application for a PyTorch model that has been trained with MONAI.\n",
    "\n",
    "### Using Google Colab\n",
    "\n",
    "This notebook has the pip command for installing MONAI and will be added to any subsequent notebook.\n",
    "\n",
    "**Required Packages for Colab Execution**\n",
    "\n",
    "Execute the following cell to install MONAI the first time a colab notebook is run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import clara\" || pip install -qU \"clara-viz\"\n",
    "!python -c \"import itk\" || pip install -qU \"itk\"\n",
    "!python -c \"import pydicom\" || pip install -qU \"pydicom\"\n",
    "!python -c \"import monai\" || pip install -qU \"monai[nibabel]\"\n",
    "!python -c \"import monai.deploy\" || pip install -qU \"monai-deploy-app-sdk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you're having issues with imports, try to \"Restart Kernel\" for Jupyter from the \"Kernel\" dropdown menu.\n",
    "\n",
    "**Enabling GPU Support**\n",
    "\n",
    "To use GPU resources through Colab, change the runtime to GPU:\n",
    "\n",
    "1. From the **\"Runtime\"** menu select **\"Change Runtime Type\"**\n",
    "2. Choose **\"GPU\"** from the drop-down menu\n",
    "3. Click **\"SAVE\"**\n",
    "\n",
    "This will reset the notebook and probably ask you if you are a robot (these instructions assume you are not). Running\n",
    "\n",
    "**!nvidia-smi**\n",
    "\n",
    "in a cell will verify this has worked and show you what kind of hardware you have access to.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Creating a Segmentation App with MONAI Deploy App SDK\n",
    "\n",
    "Deploying AI models requires integration with a clinical imaging network, even in a for-research-use setting. This requirement means that the AI deployment application will need to support standards-based imaging protocols like the DICOM protocol for Radiological imaging.\n",
    "\n",
    "Typically, DICOM network communication, either in DICOM TCP/IP network protocol or DICOMWeb, would be handled by DICOM devices or services, e.g., MONAI Deploy Informatics Gateway. So the deployment application itself would only need to use DICOM Part 10 files as input and save the AI result in DICOM Part10 file(s). For segmentation, the DICOM instance file could be a DICOM Segmentation object or a DICOM RT Structure Set, and for classification, DICOM Structure Report and/or DICOM Encapsulated PDF.\n",
    "\n",
    "During model training, input and label images are typically in non-DICOM volumetric image format, e.g., NIfTI and PNG, converted from a specific DICOM study series. Furthermore, the voxel spacings were most likely re-sampled to be uniform for all images. When integrated with imaging networks and receiving DICOM instances from modalities and Picture Archiving and Communications System, PACS, an AI deployment application may have to deal with a whole DICOM study with multiple series, whose images' spacing may not be the same as expected by the trained model. To address these cases consistently and efficiently, MONAI Deploy Application SDK provides classes, called operators, to parse DICOM studies, select specific series with application-defined rules, and convert the selected DICOM series into domain-specific image format along with meta-data representing the pertinent DICOM attributes.\n",
    "\n",
    "The following sections will demonstrate how to create a MONAI Deploy application package using the MONAI Deploy App SDK.\n",
    "\n",
    "---\n",
    " > **Note**: For local testing, if there is a lack of DICOM Part 10 files, one can use open source programs, e.g., 3D Slicer, to convert NIfTI to DICOM files.\n",
    "---\n",
    "\n",
    "### Contents\n",
    "* [Setup](#setup)\n",
    "* [Creating Operator Class](#create_op)\n",
    "* [Executing App Locally](#execute_app_local)\n",
    "* [Write Files to Disk](#write_files)\n",
    "* [Run App using CLI](#run_cli)\n",
    "* [Packing App as Docker Image](#package_app)\n",
    "* [Clara Viz](#claraviz)\n",
    "* [Exercise](#exercise)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Creating Operators and connecting them in the Application class\n",
    "\n",
    "We will implement an application that consists of five Operators:\n",
    "\n",
    "- **DICOMDataLoaderOperator**:\n",
    "    - **Input(dicom_files)**: a folder path ([`DataPath`](/modules/_autosummary/monai.deploy.core.domain.DataPath))\n",
    "    - **Output(dicom_study_list)**: a list of DICOM studies in memory (List[[`DICOMStudy`](/modules/_autosummary/monai.deploy.core.domain.DICOMStudy)])\n",
    "- **DICOMSeriesSelectorOperator**:\n",
    "    - **Input(dicom_study_list)**: a list of DICOM studies in memory (List[[`DICOMStudy`](/modules/_autosummary/monai.deploy.core.domain.DICOMStudy)])\n",
    "    - **Input(selection_rules)**: a selection rule (Dict)\n",
    "    - **Output(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "- **DICOMSeriesToVolumeOperator**:\n",
    "    - **Input(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "    - **Output(image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "- **SpleenSegOperator**:\n",
    "    - **Input(image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Output(seg_image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "- **DICOMSegmentationWriterOperator**:\n",
    "    - **Input(seg_image)**: a segmentation image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Input(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "    - **Output(dicom_seg_instance)**: a file path ([`DataPath`](/modules/_autosummary/monai.deploy.core.domain.DataPath))\n",
    "\n",
    "\n",
    "---\n",
    " > **Note**: The `DICOMSegmentationWriterOperator` needs both the segmentation image and the original DICOM series meta-data to use the patient demographics and the DICOM Study level attributes.\n",
    "---\n",
    "\n",
    "The workflow of the application would look like this.\n",
    "\n",
    "![DICOM Operator Workflow](images/dicom_workflow.png)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "<a id='setup'></a>\n",
    "## 0 Setup\n",
    "\n",
    "### 0.1 Setup environment\n",
    "\n",
    "We'll set up a variable to point to the 03_files folder, where we're storing data throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_ROOT=\"data/03_files/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you're having issues with imports, try to \"Restart Kernel\" for Jupyter from the \"Kernel\" dropdown menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Data required for all of the MONAI Deploy Notebooks\n",
    "We're going to download sample images and python files required for running the MONAI Deploy Jupyter Notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/zephyrie/monai-bootcamp/releases/download/monai-deploy-data-v0.1/deploy_data.zip\n",
    "!unzip deploy_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### 0.2 Setup imports\n",
    "\n",
    "Let's import necessary classes/decorators to define Application and Operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from os import path\n",
    "\n",
    "from numpy import uint8\n",
    "\n",
    "import monai.deploy.core as md\n",
    "from monai.deploy.core import ExecutionContext, Image, InputContext, IOType, Operator, OutputContext\n",
    "from monai.deploy.operators.monai_seg_inference_operator import InMemImageReader, MonaiSegInferenceOperator\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    EnsureChannelFirstd,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    ToTensord,\n",
    "    KeepLargestConnectedComponentd,\n",
    ")\n",
    "\n",
    "from monai.deploy.core import Application, resource\n",
    "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
    "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator\n",
    "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
    "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
    "# from monai.deploy.operators.clara_viz_operator import ClaraVizOperator\n",
    "\n",
    "import clara.viz\n",
    "from monai.deploy.operators.dicom_text_sr_writer_operator import DICOMTextSRWriterOperator, EquipmentInfo, ModelInfo\n",
    "from typing import Text\n",
    "import pydicom\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "<a id='create_op'></a>\n",
    "## 1. Creating Operator classes\n",
    "\n",
    "### 1.1 Creating Model Specific Inference Operator classes\n",
    "\n",
    "Each Operator class inherits [Operator](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.Operator.html) class and input/output properties are specified by using [@input](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.input.html)/[@output](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.output.html) decorators.\n",
    "\n",
    "Business logic would be implemented in the <a href=\"https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.Operator.html#monai.deploy.core.Operator.compute\">compute()</a> method.\n",
    "\n",
    "The App SDK provides a `MonaiSegInferenceOperator` class to perform segmentation prediction with a Torch Script model. For consistency, this class uses MONAI dictionary-based transforms, as `Compose` object, for pre and post transforms. The model-specific inference operator will then only need to create the pre and post transform `Compose` based on what has been used in the model training and validation. Note that for deploy application, `ignite` is not needed nor supported.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### 1.2 SpleenSegOperator\n",
    "\n",
    "The `SpleenSegOperator` gets as input an in-memory [Image](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.domain.Image.html) object that has been converted from a DICOM CT series by the preceding `DICOMSeriesToVolumeOperator`, and as output in-memory segmentation [Image](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.domain.Image.html) object.\n",
    "\n",
    "The `pre_process` function creates the pre-transforms `Compose` object. For `LoadImage`, a specialized `InMemImageReader`, derived from MONAI `ImageReader`, is used to convert the in-memory pixel data and return the `numpy` array as well as the meta-data. Also, the DICOM input pixel spacings are often not the same as expected by the model, so the `Spacingd` transform must be used to re-sample the image with the expected spacing.\n",
    "\n",
    "The `post_process` function creates the post-transform `Compose` object. The `SaveImageD` transform class is used to save the segmentation mask as NIfTI image file, which is optional as the in-memory mask image will be passed down to the DICOM Segmentation writer for creating a DICOM Segmentation instance. The `Invertd` must also be used to revert the segmentation image's orientation and spacing to be the same as the input.\n",
    "\n",
    "When the `MonaiSegInferenceOperator` object is created, the `ROI` size is specified, as well as the transform `Compose` objects. Furthermore, the dataset image key names are set accordingly.\n",
    "\n",
    "Loading of the model and performing the prediction are encapsulated in the `MonaiSegInferenceOperator` and other SDK classes. Once the inference is completed, the segmentation [Image](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.domain.Image.html) object is created and set to the output (<a href=\"https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.OutputContext.html#monai.deploy.core.OutputContext.set\">op_output.set(value, label)</a>), by the `MonaiSegInferenceOperator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "@md.input(\"image\", Image, IOType.IN_MEMORY)\n",
    "@md.output(\"seg_image\", Image, IOType.IN_MEMORY)\n",
    "@md.output(\"result_text\", Text, IOType.IN_MEMORY)\n",
    "@md.env(pip_packages=[\"monai==0.8.0\", \"torch>=1.5\", \"numpy>=1.20\", \"nibabel\"])\n",
    "class SpleenSegOperator(Operator):\n",
    "    \"\"\"Performs Spleen segmentation with a 3D image converted from a DICOM CT series.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        super().__init__()\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "\n",
    "        input_image = op_input.get(\"image\")\n",
    "        if not input_image:\n",
    "            raise ValueError(\"Input image is not found.\")\n",
    "\n",
    "        output_path = context.output.get().path\n",
    "\n",
    "        # This operator gets an in-memory Image object, so a specialized ImageReader is needed.\n",
    "        _reader = InMemImageReader(input_image)\n",
    "        pre_transforms = self.pre_process(_reader)\n",
    "        post_transforms = self.post_process(pre_transforms, path.join(output_path, \"prediction_output\"))\n",
    "\n",
    "        # Delegates inference and saving output to the built-in operator.\n",
    "        infer_operator = MonaiSegInferenceOperator(\n",
    "            (160,160,160,),\n",
    "            pre_transforms,\n",
    "            post_transforms,\n",
    "        )\n",
    "\n",
    "        # Setting the keys used in the dictionary based transforms may change.\n",
    "        infer_operator.input_dataset_key = self._input_dataset_key\n",
    "        infer_operator.pred_dataset_key = self._pred_dataset_key\n",
    "\n",
    "        # Now let the built-in operator handles the work with the I/O spec and execution context.\n",
    "        infer_operator.compute(op_input, op_output, context)\n",
    "        \n",
    "    def pre_process(self, img_reader) -> Compose:\n",
    "        \"\"\"Composes transforms for preprocessing input before predicting on a model.\"\"\"\n",
    "\n",
    "        my_key = self._input_dataset_key\n",
    "        return Compose(\n",
    "            [\n",
    "                LoadImaged(keys=my_key, reader=img_reader),\n",
    "                EnsureChannelFirstd(keys=my_key),\n",
    "                Spacingd(keys=my_key, pixdim=[1.0, 1.0, 1.0], mode=[\"bilinear\"], align_corners=True),\n",
    "                ScaleIntensityRanged(keys=my_key, a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                CropForegroundd(keys=my_key, source_key=my_key),\n",
    "                ToTensord(keys=my_key),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def post_process(self, pre_transforms: Compose, out_dir: str = \"./prediction_output\") -> Compose:\n",
    "        \"\"\"Composes transforms for postprocessing the prediction results.\"\"\"\n",
    "\n",
    "        pred_key = self._pred_dataset_key\n",
    "        return Compose(\n",
    "            [\n",
    "                Activationsd(keys=pred_key, softmax=True),\n",
    "                AsDiscreted(keys=pred_key, argmax=True),\n",
    "                Invertd(keys=pred_key, transform=pre_transforms, orig_keys=self._input_dataset_key, nearest_interp=True),\n",
    "                ###### uncomment line below for Exercise 3\n",
    "                # KeepLargestConnectedComponentd(keys=pred_key,applied_labels=[1]),\n",
    "                SaveImaged(keys=pred_key, output_dir=out_dir, output_postfix=\"seg\", output_dtype=uint8, resample=False),\n",
    "            ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### 1.3 Creating Application class\n",
    "\n",
    "Our application class would look like below.\n",
    "\n",
    "It defines `App` class, inheriting [Application](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.Application.html) class.\n",
    "\n",
    "The requirements (resource and package dependency) for the App can be specified by using [@resource](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.resource.html) and [@env](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.env.html) decorators.\n",
    "\n",
    "The base class method, `compose`, is overridden. Objects required for DICOM parsing, series selection (selecting the first series for the current release), pixel data conversion to volume image, and segmentation instance creation are created, so is the model-specific `SpleenSegOperator`. The execution pipeline, as a Directed Acyclic Graph, is created by connecting these objects through <a href=\"https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.Application.html#monai.deploy.core.Application.add_flow\">self.add_flow()</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "We have multiple powerful operators in this application:\n",
    "1. DICOMDataLoaderOperator\n",
    "2. DICOMSeriesSelectorOperator\n",
    "3. DICOMSeriesToVolumeOperator\n",
    "4. SpleenSegOperator\n",
    "5. DICOMSegmentationWriterOperator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "@resource(cpu=1, gpu=1, memory=\"7Gi\")\n",
    "class AISpleenSegApp(Application):  \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def compose(self):\n",
    "\n",
    "        study_loader_op = DICOMDataLoaderOperator()\n",
    "        series_selector_op = DICOMSeriesSelectorOperator()\n",
    "        ### Line below is for the exercise \n",
    "        # series_selector_op = DICOMSeriesSelectorOperator(Sample_Rules_Text)\n",
    "        series_to_vol_op = DICOMSeriesToVolumeOperator()\n",
    "        # Creates DICOM Seg writer with segment label name in a string list\n",
    "        dicom_seg_writer = DICOMSegmentationWriterOperator(seg_labels=[\"Spleen\"])\n",
    "\n",
    "        # Creates the model specific segmentation operator\n",
    "        spleen_seg_op = SpleenSegOperator()\n",
    "\n",
    "        # Creates the DAG by linking the operators\n",
    "        self.add_flow(study_loader_op, series_selector_op, {\"dicom_study_list\": \"dicom_study_list\"})\n",
    "        self.add_flow(series_selector_op, series_to_vol_op, {\"study_selected_series_list\": \"study_selected_series_list\"})\n",
    "        self.add_flow(series_to_vol_op, spleen_seg_op, {\"image\": \"image\"})\n",
    "\n",
    "        self.add_flow(series_selector_op, dicom_seg_writer, {\"study_selected_series_list\": \"study_selected_series_list\"})\n",
    "        self.add_flow(spleen_seg_op, dicom_seg_writer, {\"seg_image\": \"seg_image\"})\n",
    "        \n",
    "        ####  For Exercise #3 uncomment lines below\n",
    "        # volume_calculate_operator=CalculateVolumeOperator()\n",
    "        # self.add_flow(spleen_seg_op,volume_calculate_operator, {\"seg_image\": \"seg_image\"})\n",
    "        \n",
    "        ####  For Exercise #4 add DICOM SR\n",
    "        # my_model_info = ModelInfo(\"MONAI WG Trainer\", \"Segmentation models\", \"0.1\", \"xyz\")\n",
    "        # my_equipment = EquipmentInfo(manufacturer=\"MOANI Deploy App SDK\", manufacturer_model=\"DICOM SR Writer\")\n",
    "        # my_special_tags = {\"SeriesDescription\": \"Not for clinical use. The result is for research use only.\"}\n",
    "        # dicom_sr_operator = DICOMTextSRWriterOperator(\n",
    "        #     copy_tags=False, model_info=my_model_info, equipment_info=my_equipment, custom_tags=my_special_tags)        \n",
    "        # self.add_flow(series_selector_op, dicom_sr_operator, {\"study_selected_series_list\": \"study_selected_series_list\"})\n",
    "        # self.add_flow(volume_calculate_operator, dicom_sr_operator, {\"result_text\": \"classification_result\"})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "<a id='execute_app_local'></a>\n",
    "## 2. Executing app locally\n",
    "\n",
    "We can execute the app in the Jupyter notebook. Note that the DICOM files of the CT Abdomen series must be present in the `dcm` and the Torch Script model at `model.ts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "app = AISpleenSegApp()\n",
    "\n",
    "app.run(input=NOTEBOOK_ROOT+\"/input\", output=NOTEBOOK_ROOT+\"/output\", model=NOTEBOOK_ROOT+\"/model.ts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### 2.1 Check Output\n",
    "Let's check out the output DCM files we produced. You can see we have a DICOM SEG, and after our exercise later in the notebook, we'll also have a DICOM SR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "!ls -la {NOTEBOOK_ROOT}/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Below cell only used after exercise 7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#uncomment below lines and replace dcmSRPath with file produced \n",
    "#dcmSRPath=\"1.2.826.0.1.3680043.8.498.51905453107544020300500494684680939405_SR.dcm\"\n",
    "#pydicom.read_file(NOTEBOOK_ROOT+\"/output/\"+dcmSRPath) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "<a id='write_file'></a>\n",
    "## 3. Write code to Disk\n",
    "\n",
    "Once the application is verified inside the Jupyter notebook, we can write the Python code into Python files in an application folder.\n",
    "\n",
    "The application folder structure would look like below:\n",
    "\n",
    "```bash\n",
    "my_app\n",
    "├── __main__.py\n",
    "├── app.py\n",
    "└── spleen_seg_operator.py\n",
    "```\n",
    "\n",
    "---\n",
    " > **Note**: We can create a single application Python file (such as `spleen_app.py`) that includes the files' content instead of creating multiple files.\n",
    "You will see such an example in <a href=\"./02_mednist_app.html#executing-app-locally\">MedNist Classifier Tutorial</a>.\n",
    "---\n",
    "\n",
    "We have already written the code in the cells above to a `my_app` directory.\n",
    "\n",
    "The below lines are needed to execute the application code by using `python` interpreter.\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    AISpleenSegApp(do_run=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "!ls -la {NOTEBOOK_ROOT}/my_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "!cat {NOTEBOOK_ROOT}/my_app/__main__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "<a id='run_cli'></a>\n",
    "## 4. Run App on CLI\n",
    "You can run the App in one of two ways:\n",
    "- Using the python command\n",
    "- Using the 'monai-deploy' command \n",
    "\n",
    "---\n",
    " > **Note**: We are executing python code which makes developing and debugging simple.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python $NOTEBOOK_ROOT\"/my_app\" -i $NOTEBOOK_ROOT\"/input\" -o $NOTEBOOK_ROOT\"/output\" -m $NOTEBOOK_ROOT\"/model.ts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "The above command and below command both run the application, but one uses python directly, and the other uses the provided MONAI Deploy CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "!monai-deploy exec $NOTEBOOK_ROOT\"/my_app\" -i $NOTEBOOK_ROOT\"/input\" -o $NOTEBOOK_ROOT\"/output\" -m $NOTEBOOK_ROOT\"/model.ts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then use the `ls -la` comand to list the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "!ls -la  $NOTEBOOK_ROOT/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "<a id='package_app'></a>\n",
    "## 5. Package app (creating MAP Docker image)\n",
    "\n",
    "Let's package the app with [MONAI Application Packager](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/developing_with_sdk/packaging_app.html).\n",
    "\n",
    "Below we'll use the monai-deploy CLI to package the application by using the package command.  We'll pass the `my_app` folder path and use the `my_app` tag. We'll use the `-l DEBUG` option to see the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#!monai-deploy package -b nvcr.io/nvidia/pytorch:21.11-py3 $NOTEBOOK_ROOT\"/my_app\" --tag my_app:latest -m $NOTEBOOK_ROOT\"/model.ts\" -l DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "After creating the docker image, we can verify it by using the `docker image ls` command and grepping for `my_app`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#!docker image ls | grep my_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "tags": []
   },
   "source": [
    "### 5.1 Executing packaged app locally\n",
    "\n",
    "The packaged app can be run locally through [MONAI Application Runner](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/developing_with_sdk/executing_packaged_app_locally.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Launch the app\n",
    "#!monai-deploy run my_app:latest \"${NOTEBOOK_ROOT}/input\" \"${NOTEBOOK_ROOT}/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Check the output from the packaged app\n",
    "Now we can see the results from the packaged docker app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#!ls -la $NOTEBOOK_ROOT/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "tags": []
   },
   "source": [
    "<a id='claraviz'></a>\n",
    "## 6. Visualize the Spleen Segmentation using Clara Viz\n",
    "\n",
    "#### 6.1 Convert DICOM to NIfTI\n",
    "\n",
    "First, we'll need to convert our DICOM results to NifTI. To do that, we'll use dcm2niix, a tool designed to convert neuroimaging data from the DICOM format to the NIfTI format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/rordenlab/dcm2niix/releases/latest/download/dcm2niix_lnx.zip -O dcm2niix_lnx.zip\n",
    "!unzip -o dcm2niix_lnx.zip && rm dcm2niix_lnx.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!./dcm2niix -f %i -z y -o $NOTEBOOK_ROOT\"output\" $NOTEBOOK_ROOT\"/input/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "#### 6.2 Visualize segmentation\n",
    "\n",
    "[NVIDIA Clara Viz](https://github.com/NVIDIA/clara-viz) is a platform for visualizing 2D/3D medical imaging data. It enables building applications that leverage powerful volumetric visualization using CUDA-based ray tracing.\n",
    "\n",
    "Clara Viz offers a Python Wrapper for rapid experimentation. It also includes a collection of visual widgets for performing interactive medical image visualization in Jupyter Lab notebooks which we'll use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from clara.viz.core import DataDefinition\n",
    "from clara.viz.widgets import Widget\n",
    "from ipywidgets import interactive, Dropdown, Box, VBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "imagePath=NOTEBOOK_ROOT+'/output/123456.nii.gz'\n",
    "labelPath=NOTEBOOK_ROOT+'/output/prediction_output/1.2.826.0.1.3680043.2.1125.1/1.2.826.0.1.3680043.2.1125.1_seg.nii.gz'\n",
    "\n",
    "data_definition = DataDefinition()\n",
    "data_definition.append(imagePath,'DXYZ')\n",
    "data_definition.append(labelPath, 'MXYZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "widget = Widget()\n",
    "widget.select_data_definition(data_definition)\n",
    "# default view mode is 'CINEMATIC' switch to 'SLICE_SEGMENTATION' since we have no transfer functions defined\n",
    "widget.settings[\"Views\"][0][\"mode\"] = \"SLICE_SEGMENTATION\"\n",
    "widget.settings[\"Views\"][0][\"cameraName\"] = \"Top\"\n",
    "widget.set_settings()\n",
    "\n",
    "# add controls\n",
    "def set_view_mode(view_mode):\n",
    "    widget.settings[\"Views\"][0][\"mode\"] = view_mode\n",
    "    if view_mode == \"CINEMATIC\":\n",
    "        widget.settings[\"Views\"][0][\"cameraName\"] = \"Perspective\"\n",
    "    elif widget.settings[\"Views\"][0][\"cameraName\"] == \"Perspective\":\n",
    "        widget.settings[\"Views\"][0][\"cameraName\"] = \"Top\"\n",
    "    widget.set_settings()\n",
    "\n",
    "widget_view_mode = interactive(\n",
    "    set_view_mode,\n",
    "    view_mode=Dropdown(\n",
    "        options=[(\"Cinematic\", \"CINEMATIC\"), (\"Slice\", \"SLICE\"), (\"Slice Segmentation\", \"SLICE_SEGMENTATION\")],\n",
    "        value=\"SLICE_SEGMENTATION\",\n",
    "        description=\"View mode\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "def set_camera(camera):\n",
    "    if widget.settings[\"Views\"][0][\"mode\"] != \"CINEMATIC\":\n",
    "        widget.settings[\"Views\"][0][\"cameraName\"] = camera\n",
    "        widget.set_settings()\n",
    "widget_set_camera = interactive(set_camera, camera=Dropdown(options=[\"Top\", \"Right\", \"Front\"], value=\"Top\", description=\"Camera\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "#### Clara Viz Controls\n",
    "\n",
    "After running the cell below, you should see the visualization of the image and segmentation. \n",
    "- You can use the scroll wheel to zoom in/out\n",
    "- Left-click hold then up down to go through the slices \n",
    "- Middle-click hold to pan\n",
    "\n",
    "You can select a view from the drop-down menu to view:\n",
    "- Render view\n",
    "- Image only \n",
    "- Image and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "display(Box([widget, VBox([widget_view_mode, widget_set_camera])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "<a id='exercise'></a>\n",
    "## 7. Exercise\n",
    "\n",
    "### 7.1 Clean up the segmentation using Connected Components\n",
    "\n",
    "If you go back to the segmentation visualization and carefully examine it, you will see some small parts that aren't relevant and that we could remove. For this, you can use the KeepLargestConnectedComponent transform from MONAI Core. Check out [KeepLargestConnectedComponentd](https://docs.monai.io/en/stable/transforms.html).\n",
    "\n",
    "**Hint**: you can add the line `KeepLargestConnectedComponentd(keys=pred_key,applied_labels=[1])` in the post-transformations of your app.\n",
    "\n",
    "After adding the post-transform, re-run your app and confirm with Clara Viz that the small areas are removed.\n",
    "\n",
    "### 7.2 Add DICOM Selection Rules\n",
    "We mentioned earlier that you could pass rules to filter on the series your AI workflow should process. Now, go back and pass in a rule and re-run your code. \n",
    "\n",
    "**Hints**:\n",
    "- In `AISpleenSegApp` try passing in `Sample_Rules_Text` to the `DICOMSeriesSelectorOperator` \n",
    "- Try changing the rule to MR and see what happens \n",
    "\n",
    "Below, you'll find a rules sample, written in JSON, for selecting a CT series. If the study has more than 1 CT series, then all of them will be selected. Please see more detail in [DICOMSeriesSelectorOperator](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.operators.DICOMSeriesSelectorOperator.html).\n",
    "```\n",
    "Sample_Rules_Text = \"\"\"\n",
    "{\n",
    "    \"selections\": [\n",
    "        {\n",
    "            \"name\": \"CT Series\",\n",
    "            \"conditions\": {\n",
    "                \"StudyDescription\": \"(.*?)\",\n",
    "                \"Modality\": \"(?i)CT\",\n",
    "                \"SeriesDescription\": \"(.*?)\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "In the `AISpleenSegApp` code above, you'll find comments for including the rule definition in the DICOM Series Selector. Make sure that you comment out the original DICOM Series Selector that doesn't have a parameter. You will also need to ensure that you instantiate a rule selection in a variable named `Sample_Rules_Text`.\n",
    "\n",
    "```\n",
    "series_selector_op = DICOMSeriesSelectorOperator(Sample_Rules_Text)\n",
    "```\n",
    "\n",
    "Now re-run your app and see how the series selector works.\n",
    "You should also change the rules a bit and see how that would work.\n",
    "\n",
    "### 7.3 Calculate the spleen volume\n",
    "\n",
    "Now, go back and calculate the volume of the segmented spleen.\n",
    "\n",
    "**Hints**:\n",
    "- Write a new operator to take the segmentation as an in-memory image, then count the number of non-zero pixels.\n",
    "- You can use the code below as a starting point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@md.input #<---- what should be the input ?> \n",
    "@md.output # <--- what should be the output \n",
    "@md.env(pip_packages=[\"monai==0.8.0\", \"torch>=1.5\", \"numpy>=1.20\", \"nibabel\"])\n",
    "class CalculateVolumeOperator(Operator):\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        super().__init__()\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "        print(\"hello from my new operator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "You will also need to add a flow in the `compose` function to connect the `AISpleenSegApp` operator to the `CalculateVolumeOperator`.\n",
    "\n",
    "You'll find the code below commented out in your current compose function.  You can uncomment the code after you've written your CalculateVolumeOperator function to test your solution.\n",
    "\n",
    "```\n",
    "volume_calculate_operator=CalculateVolumeOperator()\n",
    "self.add_flow(spleen_seg_op,volume_calculate_operator, {\"seg_image\": \"seg_image\"})\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Full working code for the `CalculateVolumeOperator` is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "@md.input(\"seg_image\", Image, IOType.IN_MEMORY)\n",
    "@md.output(\"result_text\", Text, IOType.IN_MEMORY)\n",
    "@md.env(pip_packages=[\"monai==0.8.0\", \"torch>=1.5\", \"numpy>=1.20\", \"nibabel\"])\n",
    "class CalculateVolumeOperator(Operator):\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        super().__init__()\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "        print(\"hello from my new operator\")\n",
    "        \n",
    "        seg = op_input.get(\"seg_image\")\n",
    "        # In case the Image object is not in the input, and input is the seg image file folder path.\n",
    "        if not isinstance(seg, Image):\n",
    "            raise ValueError(\"Input 'seg_image' is not Image or DataPath.\")\n",
    "        print (f\"------got seg\")\n",
    "        seg_np = seg.asnumpy()\n",
    "        print (f\"shape is {seg_np.shape}\")\n",
    "        count=np.count_nonzero(seg_np)\n",
    "        print (f\"------pixel count is {count}\")\n",
    "        op_output.set(str(count), \"result_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 7.4 Write the spleen volume to DICOM SR\n",
    "\n",
    "Now that you have calculated the spleen volume, you can write it to a DICOM SR.\n",
    "\n",
    "**Hints**:\n",
    "- Write the count from the `CalculateVolumeOperator` to the DICOM SR text field \n",
    "- Add flow from `CalculateVolumeOperator` to `dicomSR` operator\n",
    "- You can copy the DICOM SR from the previous notebook or uncomment the relevant lines in your `AISpleenSegApp` compose function for Exercise #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#conclusion'></a>\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we have walked through creating a segmentation task and utilizing the existing DICOM Operators provided by MONAI Deploy App SDK. You've run the application in Jupyter, locally using Python and the MONAI Deploy CLI, and finally, you packaged the application using docker and executed the newly created container image.\n",
    "\n",
    "You also worked on some additional exercises to help you get familiar with working in the MONAI Deploy Workflow.\n",
    "\n",
    "### What's Next\n",
    "You're now ready to use MONAI Deploy on your project or start contributing to the project.\n",
    "\n",
    "[MONAI Deploy Repo](https://github.com/Project-MONAI/monai-deploy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
