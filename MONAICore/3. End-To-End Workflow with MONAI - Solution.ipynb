{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"monai.png\" style=\"width: 700px;\"/>\n",
    "\n",
    "Welcome to the MONAI bootcamp! This notebook will introduce you to an end-to-end working in MONAI using a standard PyTorch loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Google Colab\n",
    "\n",
    "This notebook has the pip command for installing MONAI and will be added to any subsequent notebook.\n",
    "\n",
    "**Enabling GPU Support**\n",
    "\n",
    "To use GPU resources through Colab, change the runtime to GPU:\n",
    "\n",
    "1. From the **\"Runtime\"** menu select **\"Change Runtime Type\"**\n",
    "2. Choose **\"GPU\"** from the drop-down menu\n",
    "3. Click **\"SAVE\"**\n",
    "\n",
    "This will reset the notebook and probably ask you if you are a robot (these instructions assume you are not). Running\n",
    "\n",
    "**!nvidia-smi**\n",
    "\n",
    "in a cell will verify this has worked and show you what kind of hardware you have access to.    \n",
    "\n",
    "**Required Packages for Colab Execution**\n",
    "\n",
    "Execute the following cell to install MONAI the first time a colab notebook is run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -qU \"monai[ignite, nibabel, torchvision, tqdm]==1.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end Training with Pytorch\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've covered a lot of material and now it's time to apply the things that we've learned in an end-to-end example.  First, we're going to use the basic PyTorch paradigm for training our model.  We'll then look at how to train using the Ignite workflows to make things even easier!\n",
    "\n",
    "\n",
    "## End-to-End Training Workflow\n",
    "\n",
    "To help guide you through training your first model using MONAI, this guide will will cover five key phases:\n",
    "\n",
    "1. **Setting up our Dataset and exploring the data**\n",
    "2. **Preparing datasets and transforms**\n",
    "3. **Define your network and create our PyTorch training loop**\n",
    "4. **Evaluate your model and understand the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import monai\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.data import decollate_batch, partition_dataset_classes\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirst,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    EnsureType\n",
    ")\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Setting up our Dataset and exploring the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup data directory\n",
    "\n",
    "We'll create a temporary directory for all the MONAI data we're going to be using called MONAI_DATA_DIRECTORY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the MedNIST dataset\n",
    "The `MedNIST` dataset was gathered from several sets from [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions),\n",
    "[the RSNA Bone Age Challenge](http://rsnachallenges.cloudapp.net/competitions/4),\n",
    "and [the NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest).\n",
    "\n",
    "The dataset is kindly made available by [Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic)\n",
    "under the Creative Commons [CC BY-SA 4.0 license](https://creativecommons.org/licenses/by-sa/4.0/). If you use the MedNIST dataset, please acknowledge the source.\n",
    "\n",
    "We're going to download this dataset below and extract it into our temporary MONAI Data Directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource = \"https://www.dropbox.com/s/5wwskxctvcxiuea/MedNIST.tar.gz?dl=1\"\n",
    "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
    "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set deterministic training for reproducibility\n",
    "[set_determinism](https://docs.monai.io/en/latest/utils.html?highlight=set_determinism#monai.utils.misc.set_determinism) will set the random seeds in both Numpy and PyTorch to ensure reproducibility. We'll see later that we need to go a little bit further to ensure reproducibility in a jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the image filenames from the dataset folders\n",
    "\n",
    "When using a dataset, you want to understand the basics of the images, labels, and more.  We'll start off by showing some of those basic statistics for MedNIST.\n",
    "\n",
    "We'll see that 6 different folders are representing 6 different categories: Hand, AbdomenCT, CXR, ChestCT, BreastMRI, HeadCT.  We'll be using each of these categories as our label names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "\n",
    "image_files = [\n",
    "    [\n",
    "        os.path.join(data_dir, class_names[i], x)\n",
    "        for x in os.listdir(os.path.join(data_dir, class_names[i]))\n",
    "    ]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "image_class = []\n",
    "\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "    \n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly pick images from the dataset to visualize and check\n",
    "\n",
    "We want to understand what the images we're using look like, so we'll start by visualizing a few random images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(3, 3, figsize=(8, 8))\n",
    "for i, k in enumerate(np.random.randint(num_total, size=9)):\n",
    "    im = PIL.Image.open(image_files_list[k])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xlabel(class_names[image_class[k]])\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Preparing datasets and transforms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare training, validation, and test data lists\n",
    "\n",
    "We want to split the data into 3 different sets, one for training, one for validation, and one for testing.  We'll use a ratio of 80/10/10 for those sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds, val_inds, test_inds = partition_dataset_classes(np.arange(len(image_files_list)), \n",
    "                                                            image_class,(8, 1, 1), shuffle=True)\n",
    "\n",
    "train_x = [image_files_list[i] for i in train_inds]\n",
    "train_y = [image_class[i] for i in train_inds]\n",
    "val_x = [image_files_list[i] for i in val_inds]\n",
    "val_y = [image_class[i] for i in val_inds]\n",
    "test_x = [image_files_list[i] for i in test_inds]\n",
    "test_y = [image_class[i] for i in test_inds]\n",
    "\n",
    "print(f\"Training count: {len(train_x)}, Validation count: {len(val_x)}, Test count: {len(test_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MONAI transforms, Dataset and Dataloader to pre-process data\n",
    "\n",
    "We'll define our transform using `Compose`.  In this Array of Transforms, we'll load the image, add a channel, scale its intensity, utilize a few random functions and finally create a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        EnsureChannelFirst(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=15, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose([LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity()])\n",
    "\n",
    "act = Compose([Activations(softmax=True)])\n",
    "to_onehot = Compose([AsDiscrete(to_onehot=num_class)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise the datasets and loaders for training, validation and test sets\n",
    " * Define a simple dataset, that we'll call `MedNISTDataset`, that groups:\n",
    "   * Images\n",
    "   * Labels\n",
    "   * The transforms that are to be run on the images and labels\n",
    " * Create three instances of this dataset:\n",
    "   * One for training\n",
    "   * One for validation\n",
    "   * One for testing\n",
    "   \n",
    "We'll use a batch size of 512 and employ 10 workers to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_workers = 10\n",
    "\n",
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "train_ds = MedNISTDataset(train_x, train_y, train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_ds = MedNISTDataset(val_x, val_y, val_transforms)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Define your network and create our PyTorch training loop**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define network and optimizer\n",
    "\n",
    "1. Set `learning_rate` for how much the model is updated per step\n",
    "1. The fetch a pytorch `device` for the GPU\n",
    "1. Instantiate a [densenet121](https://docs.monai.io/en/latest/networks.html?highlight=densenet#monai.networks.nets.densenet121) model instance and 'send' it to the GPU using `device`\n",
    "  * This is a standard MONAI implementation; it is capable of 2D and 3D operation but here we are using it in 2D mode\n",
    "1. We'll make use of the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = DenseNet121(spatial_dims=2, in_channels=1, out_channels=num_class).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network training\n",
    "We are hand-rolling a basic pytorch training loop here:\n",
    " * standard pytorch training loop\n",
    "   * step through each training epoch, running through the training set in batches\n",
    "   * after each epoch, run a validation pass, evaluating the network\n",
    "   * if it shows improved performance, save out the model weights\n",
    " * later we will revisit training loops in a more Ignite / MONAI fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_num = 4\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "auc_metric = ROCAUCMetric()\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "\n",
    "    epoch_loss = 0\n",
    "    step = 1\n",
    "\n",
    "    steps_per_epoch = len(train_ds) // train_loader.batch_size\n",
    "\n",
    "    # put the network in train mode; this tells the network and its modules to\n",
    "    # enable training elements such as normalisation and dropout, where applicable\n",
    "    net.train()\n",
    "    for batch_data in train_loader:\n",
    "\n",
    "        # move the data to the GPU\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "\n",
    "        # prepare the gradients for this step's back propagation\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # run the network forwards\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # run the loss function on the outputs\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # compute the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # tell the optimizer to update the weights according to the gradients\n",
    "        # and its internal optimisation strategy\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size + 1}, training_loss: {loss.item():.4f}\")\n",
    "        step += 1\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # after each epoch, run our metrics to evaluate it, and, if they are an improvement,\n",
    "    # save the model out\n",
    "    \n",
    "    # switch off training features of the network for this pass\n",
    "    net.eval()\n",
    "\n",
    "    # 'with torch.no_grad()' switches off gradient calculation for the scope of its context\n",
    "    with torch.no_grad():\n",
    "        # create lists to which we will concatenate the the validation results\n",
    "        preds = list()\n",
    "        labels = list()\n",
    "\n",
    "        # iterate over each batch of images and run them through the network in evaluation mode\n",
    "        for val_data in val_loader:\n",
    "            val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "\n",
    "            # run the network\n",
    "            val_pred = net(val_images)\n",
    "\n",
    "            preds.append(val_pred)\n",
    "            labels.append(val_labels)\n",
    "\n",
    "        # concatenate the predicted labels with each other and the actual labels with each other\n",
    "        y_pred = torch.cat(preds)\n",
    "        y = torch.cat(labels)\n",
    "\n",
    "        # we are using the area under the receiver operating characteristic (ROC) curve to determine\n",
    "        # whether this epoch has improved the best performance of the network so far, in which case\n",
    "        # we save the network in this state\n",
    "        y_onehot = [to_onehot(i) for i in decollate_batch(y)]        \n",
    "        y_pred_act = [act(i) for i in decollate_batch(y_pred)]\n",
    "        \n",
    "        auc_metric(y_pred_act, y_onehot)\n",
    "        auc_value = auc_metric.aggregate()\n",
    "        auc_metric.reset()\n",
    "        metric_values.append(auc_value)\n",
    "        \n",
    "        acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
    "        acc_metric = acc_value.sum().item() / len(acc_value)\n",
    "        \n",
    "        if auc_value > best_metric:\n",
    "            best_metric = auc_value\n",
    "            best_metric_epoch = epoch + 1\n",
    "            torch.save(net.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
    "            print(\"saved new best metric network\")\n",
    "            \n",
    "        print(\n",
    "            f\"current epoch: {epoch + 1} current AUC: {auc_value:.4f} /\"\n",
    "            f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f} /\"\n",
    "            f\" at epoch: {best_metric_epoch}\"\n",
    "        )\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the loss and metric\n",
    "\n",
    "Once we're done training we want to visualize our Loss and Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val AUC\")\n",
    "x = [(i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Evaluate your model and understand the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model on the test dataset\n",
    "\n",
    "After training and validation, we now have the best model as determined by the validation dataset.  But now we need to evaluate the model on the test dataset to check whether the final model is robust and not over-fitting.  We'll use these predictions to generate a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "net.eval()\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0].to(device),\n",
    "            test_data[1].to(device),\n",
    "        )\n",
    "        pred = net(test_images).argmax(dim=1)\n",
    "        \n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some light analytics - classification report\n",
    "\n",
    "We'll utilize scikit-learn's classification report to get the precision, recall, and f1-score for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some light analytics - confusion matrix\n",
    "\n",
    "Let's also create a confusion matrix to get a better understanding of the failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cmat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "cax = plt.matshow(cmat, cmap=\"turbo\", interpolation=\"nearest\")\n",
    "plt.colorbar(cax)\n",
    "\n",
    "cax.axes.set_xticks(list(range(len(class_names))), class_names, rotation=270)\n",
    "cax.axes.set_yticks(list(range(len(class_names))), class_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Summary**\n",
    "\n",
    "In this notebook, we went through an end-to-end workflow to train the MedNIST dataset using a densenet121 network.  Along the way, you did the following:\n",
    "- Learned about the MedNIST Data and downloaded it\n",
    "- Visualized the data to understand the images\n",
    "- Setup the datasets for use in the model training\n",
    "- Defined our transforms, datasets, network, and optimizers\n",
    "- Trained a densenet model and saved the best model as determined by the validation accuracy\n",
    "- Plotted your training results\n",
    "- Evaluated your model against the test set\n",
    "- Ran your final predictions through a classification report to understand more about your final results\n",
    "- Created a new workflow using Ignite\n",
    "- Learn more about issues with determinism and how to look out for pitfalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Assignment 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Ignite directly with MONAI. The Engine class used here is also extended by MONAI to provide further facilities related to determinism, providing a default training/evaluating iteration implementation, and dealing with the post-processing of data. These types are not necessary so those new to Ignite or already have their own Ignite-based code can integrate MONAI without having to pick up our types.\n",
    "\n",
    "Requirements:\n",
    "* Instantiate the SupervisedEvaluator Function\n",
    "* Instantiate the SupervisedTraining Function\n",
    "* Run the Ignite + MONAI Training Loop and compare your results to a the standard loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Events\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.metrics import Accuracy\n",
    "from monai.handlers import ROCAUC, ValidationHandler\n",
    "from monai.engines import SupervisedTrainer, SupervisedEvaluator\n",
    "\n",
    "train_epochs = 4\n",
    "iter_losses = []\n",
    "batch_sizes = []\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "steps_per_epoch = len(train_ds) // train_loader.batch_size\n",
    "if len(train_ds) % train_loader.batch_size != 0:\n",
    "    steps_per_epoch += 1\n",
    "\n",
    "\n",
    "def roc_auc_trans(x):\n",
    "    if isinstance(x, list):\n",
    "        pred = torch.cat([i[0][None, :] for i in x])\n",
    "        label = torch.cat([i[1][None, :] for i in x])\n",
    "        return pred, label\n",
    "\n",
    "    return act(x[\"pred\"]), to_onehot(x[\"label\"])\n",
    "\n",
    "\n",
    "def prepare_batch(batchdata, device, non_blocking):\n",
    "    img, classes = batchdata\n",
    "    return img.to(device), classes.to(device)\n",
    "\n",
    "\n",
    "evaluator = SupervisedEvaluator(\n",
    "    device=device,\n",
    "    val_data_loader=val_loader,\n",
    "    network=net,\n",
    "    postprocessing=roc_auc_trans,\n",
    "    key_val_metric={\"rocauc\": ROCAUC(output_transform=roc_auc_trans)},\n",
    "    prepare_batch=prepare_batch,\n",
    ")\n",
    "\n",
    "trainer = SupervisedTrainer(\n",
    "    device=device,\n",
    "    max_epochs=train_epochs,\n",
    "    train_data_loader=train_loader,\n",
    "    network=net,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    train_handlers=[ValidationHandler(1, evaluator)],\n",
    "    prepare_batch=prepare_batch,\n",
    ")\n",
    "\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def _end_iter(engine):\n",
    "    loss = np.average([o[\"loss\"] for o in engine.state.output])\n",
    "    batch_len = len(engine.state.batch[0])\n",
    "    epoch = engine.state.epoch\n",
    "    epoch_len = engine.state.max_epochs\n",
    "    step = engine.state.iteration + 1\n",
    "    iter_losses.append(loss)\n",
    "    batch_sizes.append(batch_len)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epoch_len}, Step {step}/{steps_per_epoch}, Loss = {loss:.4f}\")\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def run_validation(engine):\n",
    "    # the overall average loss must be weighted by batch size\n",
    "    overall_average_loss = np.average(iter_losses, weights=batch_sizes)\n",
    "    epoch_loss_values.append(overall_average_loss)\n",
    "\n",
    "    # clear the contents of iter_losses and batch_sizes for the next epoch\n",
    "    del iter_losses[:]\n",
    "    del batch_sizes[:]\n",
    "\n",
    "    # fetch and report the validation metrics\n",
    "    roc = evaluator.state.metrics[\"rocauc\"]\n",
    "    metric_values.append(roc)\n",
    "    print(f\"Evaluation for epoch {engine.state.epoch},  ROCAUC = {roc:.4f}\")\n",
    "\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "### Issues with determinism\n",
    "\n",
    "MONAI provides `monai.utils.set_determinism` for replicable training\n",
    "- Easy to not think about, especially in a jupyter / IPython notebook\n",
    "\n",
    "How many uses of `numpy.random`'s underlying global instance does this notebook have?\n",
    "- Dataset partitioning\n",
    "- Image previewing\n",
    "- MONAI transforms with randomised behaviour can be given / told to create their own internal `numpy.random.RandomState` instances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up transforms, revisited\n",
    "Requirements:\n",
    "* Update our original compose train function to use set_random_state using the given seed.\n",
    "* Understand why we don't have to use set_random_state for our original compose validation function.\n",
    "* Run the Standard PyTorch Training loop with the new Compose function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rseed = 12345678\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        EnsureChannelFirst(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=15, prob=0.5, keep_size=True).set_random_state(rseed),\n",
    "        RandFlip(spatial_axis=0, prob=0.5).set_random_state(rseed),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5).set_random_state(rseed),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose([LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "### Improving dataset partitioning\n",
    "\n",
    "Current code results in random numbers of images / labels each time it is run in each category. The solution is to use a deterministic shuffle:\n",
    "\n",
    "Requirements:\n",
    "* Utilize the partition_dataset_classes function to properly split the dataset into parts\n",
    "* Use the parts to create the new image_sets and label_sets\n",
    "* Create new train, val, and test sets for both image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = partition_dataset_classes(\n",
    "    data=np.arange(len(image_files_list)), \n",
    "    classes=image_class, \n",
    "    ratios=(8, 1, 1), \n",
    "    shuffle=True, \n",
    "    seed=rseed\n",
    ")\n",
    "\n",
    "image_sets = [list(), list(), list()]\n",
    "label_sets = [list(), list(), list()]\n",
    "\n",
    "for i, part in enumerate(parts):\n",
    "    image_sets[i] = [image_files_list[idx] for idx in part]\n",
    "    label_sets[i] = [image_class[idx] for idx in part]\n",
    "\n",
    "train_x, val_x, test_x = image_sets\n",
    "train_y, val_y, test_y = label_sets\n",
    "print(len(train_x), len(val_x), len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Next Steps**\n",
    "\n",
    "You can find more information about everything covered here on our [MONAI Documentation Page](https://docs.monai.io/).  \n",
    "\n",
    "If you're looking for more examples and tutorials, we have a repo dedicated just to that!  You can find it on our [GitHub Organization Page](https://github.com/Project-MONAI/tutorials).  We also have all of our videos from our first ever MONAI Bootcamp available on our [Youtube Channel](https://www.youtube.com/c/ProjectMONAI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "monai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
