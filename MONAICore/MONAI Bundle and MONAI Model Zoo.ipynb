{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da7cade5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"monai.png\"/></center>\n",
    "\n",
    "<p style=\"text-align: center\">Welcome to the MONAI bootcamp!</p>\n",
    "<p style=\"text-align: center\">This notebook will introduce you MONAI Bundles, the MONAI Model Zoo, and how to visualize your images using ITK Widgets.</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b8f83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using Google Colab\n",
    "\n",
    "This notebook has the pip command for installing MONAI and will be added to any subsequent notebook.\n",
    "\n",
    "**Enabling GPU Support**\n",
    "\n",
    "To use GPU resources through Colab, change the runtime to GPU:\n",
    "\n",
    "1. From the **\"Runtime\"** menu select **\"Change Runtime Type\"**\n",
    "2. Choose **\"GPU\"** from the drop-down menu\n",
    "3. Click **\"SAVE\"**\n",
    "\n",
    "This will reset the notebook and probably ask you if you are a robot (these instructions assume you are not). Running\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209707b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Verify GPU Access\n",
    "\n",
    "Running **!nvidia-smi** in a cell will verify this has worked and show you what kind of hardware you have access to.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4287ce38",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c0f02",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Required Packages for Colab Execution**\n",
    "\n",
    "Execute the following cell to install MONAI the first time a colab notebook is run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6b595",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -qU \"monai[ignite, nibabel, torchvision, tqdm, fire]==1.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd8964",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MONAI Bundle\n",
    "\n",
    "The objective of the MONAI bundle is to define a packaged model which includes the critical information necessary to allow users and programs to understand how the model is used and what purpose it is for. A bundle includes the stored weights of a single network as a pickled state dictionary plus optionally a Torchscript object and/or an ONNX object. Additional JSON files are included to store metadata about the model, information for constructing training, inference, and post-processing transform sequences, plain-text description, legal information, and other data the model creator wishes to include."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad2fe0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The key benefits of a bundle are to define the model package and support building Python-based workflows via structured configurations:\n",
    "\n",
    "- A self-contained model package includes all the necessary information.\n",
    "- A structured config can be used to easily reconstruct or prototype deep learning workflows.\n",
    "- Config files can provide good readability and usability by separating parameter settings from the Python code.\n",
    "- Config files can describe flexible workflow and components, allows for different low-level Python implementations\n",
    "- Learning paradigms at a higher level such as federated learning and AutoML can be decoupled from the component details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ace13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The key features support config to python conversion, hybrid programming, and lazy instantiation in the python program.\n",
    "\n",
    "- Build a full program from structured config and execute from CLI\n",
    "- Read config / metadata from JSON / YAML files with override at runtime\n",
    "- Refer to other python object in the config\n",
    "- Macro text replacement with content in the same / other config files\n",
    "- Verify metadata format based on predefined schema\n",
    "- Verify network input / output with fake data\n",
    "- Export to Torchscript\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ffb9b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A typical bundle example can include:\n",
    "\n",
    "```\n",
    "  ModelName\n",
    "  ┣━ configs\n",
    "  ┃  ┗━ metadata.json\n",
    "  ┣━ models\n",
    "  ┃  ┣━ model.pt\n",
    "  ┃  ┣━ *model.ts\n",
    "  ┃  ┗━ *model.onnx\n",
    "  ┗━ docs\n",
    "     ┣━ *README.md\n",
    "     ┗━ *license.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67536356",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A basic example\n",
    "\n",
    "Components as part of a workflow can be specified using `JSON` or `YAML` syntax, for example, a network architecture definition could be stored in a `demo_config.json` file with the following content:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"demo_net\": {\n",
    "    \"_target_\": \"monai.networks.nets.BasicUNet\",\n",
    "    \"spatial_dims\": 3,\n",
    "    \"in_channels\": 1,\n",
    "    \"out_channels\": 2,\n",
    "    \"features\": [16, 16, 32, 32, 64, 64]\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc62ee0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "or alternatively, in `YAML` format (`demo_config.yaml`):\n",
    "\n",
    "```yaml\n",
    "demo_net:\n",
    "  _target_: monai.networks.nets.BasicUNet\n",
    "  spatial_dims: 3\n",
    "  in_channels: 1\n",
    "  out_channels: 2\n",
    "  features: [16, 16, 32, 32, 64, 64]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba55b56b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The configuration parser can instantiate the component as a Python object:\n",
    "\n",
    "```python\n",
    "from monai.bundle import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read_config(\"demo_config.json\")\n",
    "net = config.get_parsed_content(\"demo_net\", instantiate=True)\n",
    "BasicUNet features: (16, 16, 32, 32, 64, 64).\n",
    "print(type(net))\n",
    "<class 'monai.networks.nets.basic_unet.BasicUNet'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da09d04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "or additionally, tune the input parameters then instantiate the component:\n",
    "\n",
    "```python\n",
    "config[\"demo_net\"][\"features\"] = [32, 32, 32, 64, 64, 64]\n",
    "net = config.get_parsed_content(\"demo_net\", instantiate=True)\n",
    "BasicUNet features: (32, 32, 32, 64, 64, 64).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e4aac2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Syntax examples explained\n",
    "\n",
    "A few characters and keywords are interpreted beyond the plain texts, here are examples of the syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505ebb8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To reference Python objects in configurations\n",
    "\n",
    "```\n",
    "\"@preprocessing#transforms#keys\"\n",
    "```\n",
    "\n",
    "Description: `@` character indicates a reference to another configuration value defined at `preprocessing#transforms#keys`. Where `#` indicates a sub-structure of this configuration file.\n",
    "\n",
    "```\n",
    "\"@preprocessing#1\"\n",
    "```\n",
    "\n",
    "Description: `1` is referencing as an integer, which is used to index (zero-based indexing) the `preprocessing` sub-structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d296e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To evaluate as Python expressions\n",
    "\n",
    "```\n",
    "\"$print(42)\"\n",
    "```\n",
    "\n",
    "Description: `$` is a special character to indicate evaluating `print(42)` at runtime.\n",
    "\n",
    "```\n",
    "\"$[i for i in @datalist]\"\n",
    "```\n",
    "\n",
    "Description: Create a list at runtime using the values in datalist as input.\n",
    "\n",
    "```\n",
    "\"$from torchvision.models import resnet18\"\n",
    "```\n",
    "\n",
    "Description: `$` followed by an import statement is handled slightly differently from the Python expressions. The imported module `resnet18` will be available as a global variable to the other configuration sections. This is to simplify the use of external modules in the configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062cf455",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To textually replace configuration elements\n",
    "\n",
    "```\n",
    "\"%demo_config.json#demo_net#in_channels\"\n",
    "```\n",
    "\n",
    "Description: `%` character indicates a macro to replace the current configuration element with the texts at `demo_net#in_channels` in the `demo_config.json` file. The replacement is done before instantiating or evaluating the components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c99bfc2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Instantiate a Python object\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"demo_name\":{\n",
    "    \"_target_\": \"my.python.module.Class\",\n",
    "    \"args1\": \"string\",\n",
    "    \"args2\": 42}\n",
    "}\n",
    "```\n",
    "\n",
    "Description: This dictionary defines an object with a reference name `demo_name`, with an instantiable type specified at `_target_` and with input arguments `args1` and `args2`. This dictionary will be instantiated as a Pytorch object at runtime.\n",
    "\n",
    "`_target_` is a required key by monai bundle syntax for the Python object name. `args1` and `args2` should be compatible with the Python object to instantiate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5742f048",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The command line interface\n",
    "\n",
    "In addition to the Pythonic APIs, a few command line interfaces (CLI) are provided to interact with the bundle. The primary usage is:\n",
    "\n",
    "```bash\n",
    "python -m monai.bundle COMMANDS\n",
    "```\n",
    "\n",
    "where `COMMANDS` is one of the following: `run`, `verify_metadata`, `ckpt_export`, … (please see `python -m monai.bundle --help` for a list of available options).\n",
    "\n",
    "The CLI supports flexible use cases, such as overriding configs at runtime and predefining arguments in a file. To display a usage page for a command, for example run:\n",
    "\n",
    "```bash\n",
    "python -m monai.bundle run -- --help\n",
    "```\n",
    "\n",
    "The support is provided by Python Fire, please make sure the optional dependency is installed, for example, using `pip install monai[fire]` or `pip install fire`. Details on the CLI argument parsing is provided in the Python Fire Guide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76470847",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MONAI Model Zoo\n",
    "\n",
    "https://monai.io/model-zoo\n",
    "\n",
    "MONAI Model Zoo is a curated library of pre-trained models, allowing data scientists and clinical researchers to jumpstart AI development. Both NVIDIA and partners across KCL, Charite, Warwick, Vanderbilt, and Mayo Clinic have contributed pre-trained models to MONAI’s open-source community. Over 15 pre-trained models are included: CT, MR, Pathology, and Endoscopy that cover segmentation, classification, registration and GAN based models. They are packaged as MONAI Bundles that can be accessed within a single click, establishing a common standard for reproducible research & collaboration.\n",
    "\n",
    "\n",
    "The MONAI Bundle format defines portable describes of deep learning models. A bundle includes the critical information necessary during a model development life cycle and allows users and programs to understand the purpose and usage of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50947d0d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spleen Segmentation Bundle Example\n",
    "\n",
    "We're going to use a the Spleen Segmentation Model and the Spleen Dataset from the Medical Segmentation Decathalon to showcase an example of how to use the Model Zoo and Bundle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2809f24a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f2e3c5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import monai\n",
    "import tempfile\n",
    "from monai.apps import download_and_extract\n",
    "from monai.bundle import ConfigParser\n",
    "from monai.data import decollate_batch\n",
    "from monai.handlers import MLFlowHandler\n",
    "from monai.config import print_config\n",
    "from monai.visualize.utils import blend_images\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "from skimage.measure import marching_cubes\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c031de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Setup data directory\n",
    "\n",
    "You can specify a directory with the MONAI_DATA_DIRECTORY environment variable. This allows you to save results and reuse downloads. If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7be451",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fab76f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Download spleen dataset\n",
    "\n",
    "Downloads and extracts the dataset. The dataset comes from http://medicaldecathlon.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8577f7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\n",
    "data_dir = os.path.join(root_dir, \"Task09_Spleen\")\n",
    "print(data_dir)\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e89df-26c1-482f-832d-b93c984a37b8",
   "metadata": {},
   "source": [
    "We're going to remove some of the data since this is just an example and depending on this system it might not be able to load all of the data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe3200-b817-43a7-b860-d081a300f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find {data_dir}/imagesTs/spleen_* -type f | sort -zR | head -10 | tr '\\n' '\\0' | xargs -0 rm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655836e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Download spleen segmentation bundle\n",
    "\n",
    "We can utilize the MONAI Bundle commands to download any of the models available on the MONAI Model Zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a4d2a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "monai.bundle.download(name=\"spleen_ct_segmentation\", version=\"0.3.7\", bundle_dir=\"./zoo_dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fad9d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Run Inference on the Spleen Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69199d46",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!python -m monai.bundle run evaluating \\\n",
    "    --meta_file \"./zoo_dir/spleen_ct_segmentation/configs/metadata.json\" \\\n",
    "    --config_file \"./zoo_dir/spleen_ct_segmentation/configs/inference.json\" \\\n",
    "    --logging_file \"./zoo_dir/spleen_ct_segmentation/configs/logging.conf\" \\\n",
    "    --dataset_dir \"{data_dir}\" \\\n",
    "    --bundle_root \"./zoo_dir/spleen_ct_segmentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7813e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Full list of commands\n",
    "\n",
    "#### Execute training:\n",
    "\n",
    "```\n",
    "python -m monai.bundle run training --meta_file configs/metadata.json --config_file configs/train.json --logging_file configs/logging.conf\n",
    "```\n",
    "\n",
    "#### Override the `train` config to execute multi-GPU training:\n",
    "\n",
    "```\n",
    "torchrun --standalone --nnodes=1 --nproc_per_node=2 -m monai.bundle run training --meta_file configs/metadata.json --config_file \"['configs/train.json','configs/multi_gpu_train.json']\" --logging_file configs/logging.conf\n",
    "```\n",
    "\n",
    "Please note that the distributed training-related options depend on the actual running environment; thus, users may need to remove `--standalone`, modify `--nnodes`, or do some other necessary changes according to the machine used. For more details, please refer to [pytorch's official tutorial](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html).\n",
    "\n",
    "#### Override the `train` config to execute evaluation with the trained model:\n",
    "\n",
    "```\n",
    "python -m monai.bundle run evaluating --meta_file configs/metadata.json --config_file \"['configs/train.json','configs/evaluate.json']\" --logging_file configs/logging.conf\n",
    "```\n",
    "\n",
    "#### Override the `train` config and `evaluate` config to execute multi-GPU evaluation:\n",
    "\n",
    "```\n",
    "torchrun --standalone --nnodes=1 --nproc_per_node=2 -m monai.bundle run evaluating --meta_file configs/metadata.json --config_file \"['configs/train.json','configs/evaluate.json','configs/multi_gpu_evaluate.json']\" --logging_file configs/logging.conf\n",
    "```\n",
    "\n",
    "#### Execute inference:\n",
    "\n",
    "```\n",
    "python -m monai.bundle run evaluating --meta_file configs/metadata.json --config_file configs/inference.json --logging_file configs/logging.conf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b426d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MONAI Bundle Hybrid Programming\n",
    "\n",
    "We're going to utilize the Hybrid Programming technique to load all of the components that we'll need to load and run inference on the network.  We'll then vizualize the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52a3dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The model's config file dynamically generates the functions needed to process new data.\n",
    "\n",
    "# Define our local system and filesystem.\n",
    "output_dir = os.path.abspath(\"./monai_results\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parse the variables in the config file.\n",
    "model_config_file = os.path.join(\"./zoo_dir\", \"spleen_ct_segmentation\", \"configs\", \"inference.json\")\n",
    "model_config = ConfigParser()\n",
    "model_config.read_config(model_config_file)\n",
    "\n",
    "# Update the confir variables to match our filesystem.\n",
    "model_config[\"bundle_root\"] = \"./zoo_dir\"\n",
    "model_config[\"output_dir\"] = output_dir\n",
    "model_config[\"dataset_dir\"] = data_dir\n",
    "\n",
    "# Identify which version of the model we want to load (each version is a\n",
    "#    \"checkpoint\").  For most models, the \"best\" checkpoint is called \"model.pt\"\n",
    "#    and it is stored in the models subdir.\n",
    "checkpoint = os.path.join(\"./zoo_dir\", \"spleen_ct_segmentation\", \"models\", \"model.pt\")\n",
    "\n",
    "# Ask the config file to generate the functions needed to process new data.\n",
    "#    These functions are adapted to our system by the config variables we\n",
    "#    modified above.  The order of first defining variables and then creating the\n",
    "#    functions is critical.\n",
    "preprocessing = model_config.get_parsed_content(\"preprocessing\")\n",
    "model = model_config.get_parsed_content(\"network\").to(device)\n",
    "inferer = model_config.get_parsed_content(\"inferer\")\n",
    "postprocessing = model_config.get_parsed_content(\"postprocessing\")\n",
    "dataloader = model_config.get_parsed_content(\"dataloader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd180018-0ff0-4621-86f1-d03eaeeb6460",
   "metadata": {},
   "source": [
    "Here we'll load the Model State and make sure that eval mode is enabled.  We can then fetch data from the data loader and run our inference method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af796d3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(checkpoint, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "d = next(iter(dataloader))   \n",
    "images = d[\"image\"].to(device)\n",
    "d[\"pred\"] = inferer(images, network=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026aee12-5ea7-4827-9a24-4a8baa7f650e",
   "metadata": {},
   "source": [
    "Now that we have the results, we can visualize the results so we can see that we are correctly getting our segmentation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f2b7e-2d4b-4aa4-8305-d189897eb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 6):\n",
    "    # plot the slice 30 - 60 of image, label and blend result\n",
    "    slice_index = 10 * i\n",
    "    plt.figure(\"blend image and label\", (12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(f\"image slice {slice_index}\")\n",
    "    plt.imshow(d['image'][0, 0, :, :, slice_index], cmap=\"gray\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(f\"label slice {slice_index}\")\n",
    "    plt.imshow(d['pred'].argmax(1).cpu()[0, :, :, slice_index])\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(f\"blend slice {slice_index}\")\n",
    "    map_image = img + pre\n",
    "    plt.imshow(map_image[0, :, :, slice_index], cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7694cfc5-26c3-4559-b46c-7370364a2e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "MONAI Fix",
   "language": "python",
   "name": "monai_fix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
