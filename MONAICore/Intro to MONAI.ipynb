{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conscious-latitude",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"monai.png\"/></center>\n",
    "\n",
    "<p style=\"text-align: center\">Welcome to the MONAI bootcamp!</p>\n",
    "<p style=\"text-align: center\">This notebook will introduce you to the MONAI Core design and architecture.  You'll get some hands-on examples with transforms, dataset loaders, caching, and network.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-latin",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using Google Colab\n",
    "\n",
    "This notebook has the pip command for installing MONAI and will be added to any subsequent notebook.\n",
    "\n",
    "**Enabling GPU Support**\n",
    "\n",
    "To use GPU resources through Colab, change the runtime to GPU:\n",
    "\n",
    "1. From the **\"Runtime\"** menu select **\"Change Runtime Type\"**\n",
    "2. Choose **\"GPU\"** from the drop-down menu\n",
    "3. Click **\"SAVE\"**\n",
    "\n",
    "This will reset the notebook and probably ask you if you are a robot (these instructions assume you are not)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-witness",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Verify GPU Access\n",
    "\n",
    "Running **!nvidia-smi** in a cell will verify this has worked and show you what kind of hardware you have access to.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-colleague",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -qU \"monai[ignite, nibabel, torchvision, tqdm]==1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-feedback",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Required Packages for Colab Execution\n",
    "\n",
    "Execute the following cell to install MONAI the first time a colab notebook is run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-garage",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-qualification",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Getting Started with MONAI\n",
    "\n",
    "MONAI is a PyTorch-based, open-source framework for deep learning in healthcare imaging, part of the PyTorch Ecosystem.\n",
    "\n",
    "*Its ambitions are:*\n",
    "\n",
    "- to develop a community of academic, industrial and clinical researchers collaborating on a common foundation\n",
    "- to create state-of-the-art, end-to-end training workflows for healthcare imaging\n",
    "- to provide researchers with the optimized and standardized way to create and evaluate deep learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-addition",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MONAI End to End workflow\n",
    "\n",
    "MONAI aims to support deep learning in medical image analysis at multiple levels. This figure shows a typical example of an end-to-end workflow in a medical deep learning context:\n",
    "\n",
    "<center><img src=\"end_to_end.png\" style=\"width: 1400px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-observer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What's the Need?\n",
    "\n",
    "* Biomedical applications have specific requirements\n",
    "* Image modalities (MR, CT, US, etc.) require specific data processing functionality\n",
    "* Data formats (DICOM, NIfTI, etc.) are specific to medical applications and require specific support\n",
    "* Certain network architectures are designed for, or are highly suitable for, biomedical applications\n",
    "* Data transforms specific to biomedical applications, and to image modalities, are very useful when pre-processing data, augmenting data during training, and for post-processing\n",
    "* Reproducible science requires reproducible experiments which in turn rely on software accessible to other scientists, even if just as a common baseline\n",
    "* A community-driven library to provide solutions to these requirements reduces duplication/re-implementation\n",
    "* Baseline implementations of common networks, and implementations of networks specific to certain papers, provides a basis for comparison between others' networks and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-environment",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How Does MONAI Address This Need?\n",
    "\n",
    "MONAI provides a framework of deep learning functionality and infrastructure to meet these needs in a flexible, PyTorch-compatible way:\n",
    "* Direct support for loading and manipulating biomedical file types\n",
    "* Biomedical-data-specific transforms for regularisation and augmentation of biomedical imaging data for training, validation, and deployment\n",
    "* Library of general-purpose network, metric, and loss function definitions implementing both established and cutting-edge architectures and features\n",
    "* Set of ready-made components for training and inference to utilize computing infrastructure efficiently\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be00b37a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Enhancing Reproducible Data Science\n",
    "\n",
    "MONAI contributes to reproducible data science by making the training and distribution of experiments easier:\n",
    "* Common underlying framework aids in comparison and interoperability across user's implementations\n",
    "* Users can pick and choose components and existing networks, then contribute new code to make their results available to others\n",
    "* Reference implementations of networks from papers provide baselines for replication studies and comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-catalog",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MONAI Architecture\n",
    "By explicit design principle, MONAI provides flexible and light APIs for users with varying expertise:\n",
    "* All the core components are independent modules, easily integrated into existing PyTorch programs\n",
    "* Leverage MONAI workflows to quickly set up a robust training or evaluation program for research experiments.\n",
    "* Rich examples and demos are provided to demonstrate the key features.\n",
    "* Researchers contribute implementations based on the state-of-the-art for the latest research challenges, including:\n",
    "  * COVID-19 image analysis\n",
    "  * Dataset caching mechanisms\n",
    "  * Model Parallel execution modes\n",
    "  * and more...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-bundle",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MONAI Architecture\n",
    "\n",
    "<br>\n",
    "<center><img src=\"arch_modules_v0.4.png\" style=\"width: 1000px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-liquid",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MONAI Design Philosophy\n",
    "\n",
    "Key principles:\n",
    "* MONAI looks like PyTorch, uses/extends PyTorch types and adheres to it's general design philosophy\n",
    "* MONAI is additive on top of PyTorch, providing extensions or wrappers\n",
    "* MONAI is opt-in and incremental, no need to rewrite entire models to integrate existing code\n",
    "* MONAI is collaborative, providing adapters and loosely coupled components to ease integration with third party code\n",
    "* MONAI is PyTorch ecosystem friendly, and part of the official ecosystem!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-income",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "To help you understand more about MONAI transforms, dataset caching, and network architectures this guide will help you answer six key questions:\n",
    "\n",
    "1. **What transforms are available to help create a data pipeline for training?**\n",
    "2. **What is required to write a custom transform?**\n",
    "3. **How do I create a basic MONAI dataset with transforms?**\n",
    "4. **What is a MONAI Dataset and how does dataset caching work?**\n",
    "5. **What common datasets are provided by MONAI?**\n",
    "6. **What Network and Network components does MONAI provide and how do you use these components to create a network?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-interface",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imports\n",
    "\n",
    "Let's get started by importing our dependecies:\n",
    "* We're going to load everything that we'll need for the remainder of the notebook here\n",
    "* You'll see a lot of import statements, but we'll make sure to go over each of them throughout the rest of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baac9f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-tunisia",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Any, Mapping, Hashable\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import monai\n",
    "from monai.config import print_config\n",
    "from monai.utils import first\n",
    "from monai.config import KeysCollection\n",
    "\n",
    "from monai.data import (Dataset, ArrayDataset, create_test_image_3d, DataLoader, DataLoader, \n",
    "CacheDataset, PersistentDataset, SmartCacheDataset)\n",
    "\n",
    "from monai.transforms import (Transform, MapTransform, Randomizable, EnsureChannelFirst, EnsureChannelFirstd,\n",
    "Compose, LoadImage, LoadImaged, Lambda, Lambdad, RandSpatialCrop, RandSpatialCropd, RandGaussianNoise,\n",
    "RandGaussianNoised, Orientation, Rotate, MapTransform)\n",
    "\n",
    "from monai.apps import DecathlonDataset, TciaDataset\n",
    "from monai.apps.tcia import TCIA_LABEL_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-capture",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Verify your Configuration\n",
    "\n",
    "Before getting started, it can be helpful to verify your environment setup and make sure all of the dependecies you need are installed. MONAI provides a handy utility to make it easy with `print_config()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-saint",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-tract",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. What transforms are available to help create a data pipeline for training?\n",
    "\n",
    "\n",
    "#### Medical Image Data I/O, Processing and Augmentation\n",
    "\n",
    "Medical images require highly specialized methods for I/O, preprocessing, and augmentation. Medical images are often in specialized formats with rich meta-information, and the data volumes are often high-dimensional. These require carefully designed manipulation procedures. The medical imaging focus of MONAI is enabled by powerful and flexible image transformations that facilitate user-friendly, reproducible, optimized medical data pre-processing pipelines.\n",
    "\n",
    "<img src=\"medical_transforms.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-paste",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Transforms Support both Dictionary and Array Format Data\n",
    "\n",
    "The widely used computer vision packages (such as torchvision) focus on spatially 2D array image processing. MONAI provides more domain-specific transformations for both spatially 2D and 3D and retains the flexible transformation “compose” feature.\n",
    "\n",
    "As medical image preprocessing often requires additional fine-grained system parameters, MONAI provides transforms for input data encapsulated in python dictionaries. Users can specify the keys corresponding to the expected data fields and system parameters to compose complex transformations.\n",
    "\n",
    "There is a rich set of transforms in six categories: Crop & Pad, Intensity, IO, Post-processing, Spatial, and Utilities. For more details, please visit all the transforms in MONAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-duration",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Medical Specific Transforms\n",
    "MONAI aims at providing a comprehensive medical image specific transformations. These currently include, for example:\n",
    "\n",
    "* LoadImage: Load medical specific formats file from provided path\n",
    "* Spacing: Resample input image into the specified pixdim\n",
    "* Orientation: Change the image’s orientation into the specified axcodes\n",
    "* RandGaussianNoise: Perturb image intensities by adding statistical noises\n",
    "* NormalizeIntensity: Intensity Normalization based on mean and standard deviation\n",
    "* Affine: Transform image based on the affine parameters\n",
    "* Rand2DElastic: Random elastic deformation and affine in 2D\n",
    "* Rand3DElastic: Random elastic deformation and affine in 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-bicycle",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Create Toy Data and Temp Directory for Examples\n",
    "\n",
    "We'll create a temporary directory and populate it with a few example Nifti file-format images containing a random assortment of spheres.  We're also creating a matching segmentation pair that will be used later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-macedonia",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fn_keys = (\"img\", \"seg\")  # filename keys for image and seg files\n",
    "\n",
    "root_dir = tempfile.mkdtemp()\n",
    "filenames = []\n",
    "\n",
    "for i in range(5):\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_objs=16, rad_max=25)\n",
    "\n",
    "    im_filename = f\"{root_dir}/im{i}.nii.gz\"\n",
    "    seg_filename = f\"{root_dir}/seg{i}.nii.gz\"\n",
    "    filenames.append({\"img\": im_filename, \"seg\": seg_filename})\n",
    "\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "    nib.save(n, im_filename)\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, seg_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-theater",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Array Transforms\n",
    "\n",
    "Transforms in MONAI are callable objects accepting inputs from initial data in a dataset or previous transforms. We can create and call these directly without any infrastructure or system setup as components in MONAI are designed to be as decoupled as possible. For example we can load one of our Nifti files directly by creating the transform and calling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-litigation",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trans = Compose([LoadImage(image_only=True), EnsureChannelFirst()])\n",
    "img = trans(filenames[0][\"img\"])\n",
    "print(type(img), img.shape, img.get_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-chain",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Dictionary Transforms\n",
    "\n",
    "So far we have seen transforms which are applied to individual Numpy arrays, however for most training schemes a pipeline with multiple values is needed:\n",
    "* To address this MONAI includes transforms for operating on dictionaries of arrays, one for each equivalent array transform\n",
    "* These can be applied to named values in an input dictionary while leaving unnamed values untouched\n",
    "  * for example adding noise to an image while leaving the associated label image untouched."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6046eed8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Dictionary Transforms\n",
    "\n",
    "Earlier in the notebook we imported the dictionary equivalent transforms which have a 'd' appended to their names:\n",
    "* We'll use those transforms in this section\n",
    "* The keys argument in LoadNiftid is used to state which keys contain paths to Nifti files\n",
    "  * All other values in the input dictionary will be retained\n",
    "  * With this set we can look at the keys returned when calling the transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-kenya",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trans = LoadImaged(keys=fn_keys)\n",
    "data = trans(filenames[0])\n",
    "print(list(data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-palestinian",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is required to write a custom transform?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-wrist",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Custom Array Transform\n",
    "\n",
    "We can define our own custom transform operation in a number of ways. \n",
    "\n",
    "If a simple callable is used as an operator, `Lambda` can be used to wrap it as a transform:\n",
    "* We define in this example a transform to sum the image in the 1st (width) dimension to produce a 2D image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-conservative",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sum_width(img):\n",
    "    return img.sum(1)\n",
    "\n",
    "\n",
    "trans = Compose([LoadImage(image_only=True), EnsureChannelFirst(), Lambda(sum_width)])\n",
    "img = trans(filenames[0][\"img\"])\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-comedy",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Creating a subclass of Transform is the second method, and this has the advantage of being able to define attributes with the instantiated objects:\n",
    "* Let's define a class to sum in a chosen dimension, and use it to sum in the 2nd (height) dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-reproduction",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class SumDimension(Transform):\n",
    "    def __init__(self, dim=1):\n",
    "        self.dim = dim\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return inputs.sum(self.dim)\n",
    "\n",
    "\n",
    "trans = Compose([LoadImage(image_only=True), EnsureChannelFirst(), SumDimension(2)])\n",
    "img = trans(filenames[0][\"img\"])\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-financing",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Custom Dictionary Transform\n",
    "\n",
    "`Lambdad` applies the given callable to each array named by `keys` separately:\n",
    "* We can use this to define transforms operating on different named values in the dictionary at different points in the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-eating",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sum_width(img):\n",
    "    return img.sum(1)\n",
    "\n",
    "def max_width(img):\n",
    "    return img.max(1)\n",
    "\n",
    "trans = Compose(\n",
    "    [LoadImaged(fn_keys), EnsureChannelFirstd(fn_keys), Lambdad((\"img\",), sum_width), Lambdad((\"seg\",), max_width)]\n",
    ")\n",
    "\n",
    "imgd = trans(filenames[0])\n",
    "img = imgd[\"img\"]\n",
    "seg = imgd[\"seg\"]\n",
    "\n",
    "plt.imshow(np.hstack((img[0] * 5 / img.max(), np.squeeze(seg[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-france",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Deterministic vs non-deterministic transforms\n",
    "\n",
    "*Deterministic transforms*: Given same input, produce the same output\n",
    "\n",
    "*Non-Deterministic transforms*: Given the same input, produce randomized output each time, based on RNG\n",
    "\n",
    "MONAI's non-deterministic transforms have several useful features:\n",
    "* By default, each transform has its own RNG\n",
    "* Datasets can override this (see `ArrayDataset` below)\n",
    "* You can override it by providing either a 'seed' or a `RandomState` instance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-california",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. How do I create a basic MONAI dataset with transforms?\n",
    "\n",
    "Now that we've taken a look at transform, let's take a look at datasets:\n",
    "* With a data source and transforms defined we can now create a dataset object\n",
    "* The base class for MONAI is `Dataset`, created here to load the image Nifti files only\n",
    "* `Dataset` inherits from the Pytorch class of that name and adds only the ability to apply the given transform to selected items\n",
    "  * If you're familiar with the class from Pytorch this will work the same way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-lunch",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "images = [fn[\"img\"] for fn in filenames]\n",
    "\n",
    "transform = Compose([LoadImage(image_only=True), EnsureChannelFirst()])\n",
    "ds = Dataset(images, transform)\n",
    "img_tensor = ds[0]\n",
    "print(img_tensor.shape, img_tensor.get_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-sector",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ArrayDataset\n",
    "\n",
    "MONAI provides the `ArrayDataset` for supervised training applications:\n",
    "* Provide one pipeline for images and another for labels\n",
    "* Typically this is useful when performing augmentations on images that don't make sense for labels\n",
    "  * Adding noise, normalization, so forth\n",
    "* Both pipelines use the random state of the dataset to ensure consistency for random operations\n",
    "  * Caveat: The shared operations must be in the same order\n",
    "  * Caveat: The shared operations must be before any unshared operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec046e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ArrayDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-budget",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "images = [fn[\"img\"] for fn in filenames]\n",
    "segs = [fn[\"seg\"] for fn in filenames]\n",
    "\n",
    "img_transform = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        EnsureChannelFirst(),\n",
    "        RandSpatialCrop((128, 128, 128), random_size=False),\n",
    "        RandGaussianNoise(.5, 1, 1),\n",
    "    ]\n",
    ")\n",
    "seg_transform = Compose(\n",
    "    [LoadImage(image_only=True), EnsureChannelFirst(), RandSpatialCrop((128, 128, 128), random_size=False)]\n",
    ")\n",
    "\n",
    "ds = ArrayDataset(images, img_transform, segs, seg_transform)\n",
    "im, seg = ds[0]\n",
    "plt.imshow(np.hstack([im.numpy()[0, 48], seg.numpy()[0, 48]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-honor",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Dataset with Dictionary-based Transforms\n",
    "\n",
    "Alternatively, `Dataset` can be used with dictionary-based transforms to construct a result mapping. For training applications beyond simple input/ground-truth pairs like the above this would be more suitable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-collaboration",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trans = Compose(\n",
    "    [\n",
    "        LoadImaged(fn_keys),\n",
    "        EnsureChannelFirstd(fn_keys),\n",
    "        RandGaussianNoised((\"img\",)),\n",
    "        RandSpatialCropd(fn_keys, (128, 128, 128), random_size=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds = Dataset(filenames, trans)\n",
    "item = ds[0]\n",
    "im, seg = item[\"img\"], item[\"seg\"]\n",
    "plt.imshow(np.hstack([im.numpy()[0, 48], seg.numpy()[0, 48]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-sociology",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### DataLoader\n",
    "\n",
    "With the dataset defined, we can now create the dataloader to create data batches:\n",
    "* Inherits from Pytorch's `DataLoader` class with a few changes to the default constructor arguments\n",
    "* MONAI functionality is compatible with the PyTorch DataLoader\n",
    "  * Additional functionality adds key extensions to the standard `DataLoader`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4803e234",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Example\n",
    "* The `DataLoader` example uses five worker processes to load the actual data\n",
    "* MONAI also provides a number of `Dataset` subclasses to further improve the efficiency of this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-addiction",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(ds, batch_size=5, num_workers=5)\n",
    "batch = first(loader)\n",
    "print(list(batch.keys()), batch[\"img\"].shape)\n",
    "\n",
    "f, ax = plt.subplots(2, 1, figsize=(8, 4))\n",
    "ax[0].imshow(np.hstack(batch[\"img\"][:, 0, 64]))\n",
    "ax[1].imshow(np.hstack(batch[\"seg\"][:, 0, 64]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-squad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4. What is a MONAI Dataset and how does dataset caching work?\n",
    "\n",
    "\n",
    "Users often need to train the model with many (potentially thousands of) epochs over the data to achieve the desired model quality:\n",
    "* A native PyTorch implementation may repeatedly load data and run the same preprocessing steps for every epoch during training\n",
    "* Can be time-consuming and unnecessary, especially when the medical image volumes are large\n",
    "* By utilizing Dataset Caching, you can reduce the amount of time your system takes to load this data and preprocess it\n",
    "* Reducing your overall training time.\n",
    "\n",
    "We will demonstrate two of the Dataset subclasses here but there are additional useful specialised `Dataset`s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-filter",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What is a MONAI Dataset?\n",
    "\n",
    "A MONAI Dataset is a generic dataset with a __len__ property, __getitem__ property, and an optional callable data transform when fetching a data sample.\n",
    "\n",
    "We'll start by initializing some generic data, calling the Dataset class with the generic data, and specifying None for our transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-latest",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "items = [{\"data\": 4}, \n",
    "         {\"data\": 9}, \n",
    "         {\"data\": 3}, \n",
    "         {\"data\": 7}, \n",
    "         {\"data\": 1},\n",
    "         {\"data\": 2},\n",
    "         {\"data\": 5}]\n",
    "dataset = monai.data.Dataset(items, transform=None)\n",
    "\n",
    "print(f\"Length of dataset is {len(dataset)}\")\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-paste",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Dataset compatibility with PyTorch DataLoader\n",
    "\n",
    "MONAI datasets can be used with vanilla PyTorch DataLoader:\n",
    "* As mentioned, MONAI's `DataLoader` has additional useful functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-royal",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for item in torch.utils.data.DataLoader(dataset, batch_size=2):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-league",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What is Dataset Caching and how do I use it?\n",
    "\n",
    "MONAI provides multi-thread versions of `CacheDataset` and `LMDBDataset` to accelerate transformation pipelines during training:\n",
    " * put deterministic transforms first, and random transforms after\n",
    " * the output of the deterministic transforms is always the same, so only compute once!\n",
    " * random transforms produce different outputs each time they are used so must be computed every time\n",
    "   * can provide up to 10x training speedup in the Datasets experiment.\n",
    " \n",
    "<img src=\"cache_dataset.png\" style=\"width: 700px;\"/>\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-membrane",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To demonstrate the benefit dataset caching, we're going to construct a dataset with a slow transform:\n",
    " * To do that, we're going to call the sleep function during each of the `__call__` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-vampire",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class SlowSquare(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        MapTransform.__init__(self, keys)\n",
    "        print(f\"keys to square it: {self.keys}\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        time.sleep(1.0)\n",
    "        output = {key: x[key] ** 2 for key in self.keys}\n",
    "        return output\n",
    "\n",
    "square_dataset = Dataset(items, transform=SlowSquare(keys=\"data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-armor",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As expected, it's going to take about 7 seconds to go through all the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-laundry",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%time for item in square_dataset: print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-agriculture",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Every time we run this loop it takes roughly 7 seconds to go through all of the items:\n",
    " * 12 extra minutes of load time for 100 epochs\n",
    " * We can improve this time by utilizing caching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-passenger",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Cache Dataset\n",
    "\n",
    "When using [CacheDataset](https://docs.monai.io/en/latest/data.html?highlight=dataset#cachedataset) the caching is done when the object is initialized for the first time, so the initialization is slower than a regular dataset:\n",
    "* By caching the results of non-random preprocessing transforms, it accelerates the training data pipeline\n",
    "* If the requested data is not in the cache, all transforms will run normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-union",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "square_cached = CacheDataset(items, transform=SlowSquare(keys='data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-latter",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, repeatedly fetching the items from an initialized CacheDataset is fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-ticket",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%timeit list(square_cached)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-chapter",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Persistent Caching\n",
    "\n",
    "[PersistentDataset](https://docs.monai.io/en/latest/data.html?highlight=dataset#persistentdataset) allows for persistent storage of pre-computed values to efficiently manage larger than memory dictionary format data:\n",
    "* Again, the non-random transform components are computed when first used\n",
    "* Stored in the cache_dir for rapid retrieval on subsequent uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-prayer",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "square_persist = monai.data.PersistentDataset(items, transform=SlowSquare(keys='data'), cache_dir=\"my_cache\")\n",
    "\n",
    "%time for item in square_persist: print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-medline",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "During the initialization of the PersistentDataset we passed in the parameter \"my_cache\" for the location to store the intermediate data. We'll look at that directory below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-exhibition",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!ls my_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-hamburg",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When calling out to the dataset on the following epochs, it will not call the slow transform but used the cached data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-album",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%timeit list(square_persist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-investigator",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Fresh dataset instances can make use of the caching data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-danger",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "square_persist_1 = monai.data.PersistentDataset(items, transform=SlowSquare(keys='data'), cache_dir=\"my_cache\")\n",
    "%timeit list(square_persist_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-casino",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Caching in action\n",
    "\n",
    "- There's also a [SmartCacheDataset](https://docs.monai.io/en/latest/data.html#monai.data.SmartCacheDataset) to hide the transforms latency with less memory consumption.\n",
    "- The dataset tutorial notebook has a working example and a comparison of different caching mechanism in MONAI: https://github.com/Project-MONAI/tutorials/blob/master/acceleration/dataset_type_performance.ipynb\n",
    "\n",
    "<center><img src=\"datasets_speed.png\" style=\"width: 700px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-citizenship",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5. What common datasets are provided by MONAI?\n",
    "\n",
    "To quickly get started with popular training data in the medical domain, MONAI provides several data-specific Datasets:\n",
    "* MedNISTDataset, DecathlonDataset, etc.\n",
    "* Provides easy downloading from our AWS storage, extraction of data files and supports generation of training/evaluation items with transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-terry",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Decathlon Dataset \n",
    "\n",
    "The [DecathlonDataset](https://docs.monai.io/en/latest/data.html?highlight=dataset#decathlon-datalist) function leverages the features described throughout this notebook.  These datasets are an extension of CacheDataset covered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-brazilian",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dataset = monai.apps.DecathlonDataset(root_dir=\"./\", task=\"Task09_Spleen\", section=\"training\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-assets",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(dataset.get_properties(\"numTraining\"))\n",
    "print(dataset.get_properties(\"description\"))\n",
    "print(dataset[0]['image'].shape)\n",
    "print(dataset[0]['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-religious",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### TCIA Dataset\n",
    "\n",
    "The Cancer Imaging Archive (TCIA)](https://www.cancerimagingarchive.net/) is a service which de-identifies and hosts a large publicly available archive of medical images of cancer:\n",
    "* TCIA is funded by the [Cancer Imaging Program (CIP)](https://imaging.cancer.gov/), a part of the United States [National Cancer Institute (NCI)](https://www.cancer.gov/), and is managed by the [Frederick National Laboratory for Cancer Research (FNLCR)](https://frederick.cancer.gov/).\n",
    "* The `TciaDataset` function will automatically download and extract the TCIA datasets with accompanying DICOM segmentations, and act as PyTorch datasets to generate training/validation/test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d01816d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### TCIA Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-southeast",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Let's take the \"QIN-PROSTATE-Repeatability\" collection for example\n",
    "collection, seg_type = \"QIN-PROSTATE-Repeatability\", \"SEG\"\n",
    "\n",
    "ds = TciaDataset(\n",
    "    root_dir=\"./\",\n",
    "    collection=collection,\n",
    "    section=\"training\",\n",
    "    download=True,\n",
    "    download_len=1,\n",
    "    seg_type=seg_type,\n",
    "    progress=True,\n",
    "    cache_rate=0.0,\n",
    "    val_frac=0.2,\n",
    ")\n",
    "print(ds.datalist[0])\n",
    "print(len(ds.datalist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-module",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What Network and Network components does MONAI provide and how do you use these components to create a network?\n",
    "\n",
    "MONAI provides definitions for networks and their components that inherit directly from Pytorch Module, Sequential, etc. These general purpose networks include parameterized topologies that can easily be expanded are independent from rest of MONAI so networks can be used with existing training code.\n",
    "\n",
    "MONAI includes the following submodules:\n",
    "* layers: defines low level layers, factories for selecting Pytorch and custom layers based on dimension and other arguments\n",
    "* blocks: mid-level building blocks defining specific reusable concepts networks are constructed from\n",
    "* nets: full network definitions for common architectures, eg. UNet, VNet, Densenet,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9368782",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Blocks and networks use LayerFactory objects as generic factory for custom and PyTorch layers.\n",
    "\n",
    "MONAI provides blocks for defining:\n",
    "- Convolution with activation and regularization\n",
    "- Residual units\n",
    "- Squeeze/excitation\n",
    "- Downsampling/upsampling\n",
    "- Subpixel convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-camel",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### How do you use MONAI Layers?\n",
    "\n",
    "Network functionality represents a significant design opportunity for MONAI:\n",
    "* Pytorch is very much unopinionated in how networks are defined\n",
    "* It provides Module as a base class to create a network and a few methods that must be implemented\n",
    "* Still, there is no prescribed pattern nor much helper functionality for initializing networks.\n",
    "\n",
    "The lack of helper functionality leaves a lot of room for defining some beneficial 'best practice' patterns for constructing new networks in MONAI:\n",
    "* Although trivial, inflexible network implementations are easy enough\n",
    "* We give users a toolset that makes it much easier to build well-engineered, flexible networks and demonstrate their value by committing to use them in the networks that we build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-christmas",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from monai.networks.layers import Conv, Act, split_args, Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-client",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Convolutions\n",
    "\n",
    "The [Conv](https://docs.monai.io/en/latest/networks.html#convolution) class has two options for the first argument. The second argument must be the number of spatial dimensions, `Conv[name, dimension]`, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-learning",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(Conv[Conv.CONV, 1])\n",
    "print(Conv[Conv.CONV, 2])\n",
    "print(Conv[Conv.CONV, 3])\n",
    "print(Conv[Conv.CONVTRANS, 1])\n",
    "print(Conv[Conv.CONVTRANS, 2])\n",
    "print(Conv[Conv.CONVTRANS, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-weekend",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The configured classes are the \"vanilla\" PyTorch layers. We could create instances of them by specifying the layer arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-classification",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(Conv[Conv.CONV, 2](in_channels=1, out_channels=4, kernel_size=3))\n",
    "print(Conv[Conv.CONV, 3](in_channels=1, out_channels=4, kernel_size=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-server",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Activiation\n",
    "\n",
    "The [Act](https://docs.monai.io/en/latest/networks.html#module-monai.networks.layers.Act) classes don't require the spatial dimension information, but supports additional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-estonia",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(Act[Act.PRELU])\n",
    "Act[Act.PRELU](num_parameters=1, init=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-complement",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These could be fully specified with a tuple of `(type_name, arg_dict)`, such as `(\"prelu\", {\"num_parameters\": 1, \"init\": 0.1})`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-lebanon",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "act_name, act_args = split_args((\"prelu\", {\"num_parameters\": 1, \"init\": 0.1}))\n",
    "Act[act_name](**act_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-humanitarian",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### How do you use these components to create a network?\n",
    "\n",
    "##### Flexible Definition Networks\n",
    "\n",
    "These APIs allow for flexible definitions of networks.  Below we'll create a class called `MyNetwork` that utilizes `Conv`, `Act`, and `Pool`.  Each Network requires an `__init__` and a `forward` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-paper",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class MyNetwork(torch.nn.Module):\n",
    "    def __init__(self, dims=3, in_channels=1, out_channels=8, kernel_size=3, pool_kernel=2, act=\"relu\"):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        # convolution\n",
    "        self.conv = Conv[Conv.CONV, dims](in_channels, out_channels, kernel_size=kernel_size)\n",
    "        # activation\n",
    "        act_type, act_args = split_args(act)\n",
    "        self.act = Act[act_type](**act_args)\n",
    "        # pooling\n",
    "        self.pool = Pool[Pool.MAX, dims](pool_kernel)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-massachusetts",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Example Instantiations\n",
    "\n",
    "This network definition can be instantiated to support either 2D or 3D inputs, with flexible kernel sizes.  It becomes handy when adapting the same architecture design for different tasks, switching among 2D, 2.5D, 3D easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-wedding",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# default network instance\n",
    "default_net = MyNetwork()\n",
    "print(default_net)\n",
    "print(default_net(torch.ones(3, 1, 20, 20, 30)).shape)\n",
    "\n",
    "# 2D network instance\n",
    "elu_net = MyNetwork(dims=2, in_channels=3, act=(\"elu\", {\"inplace\": True}))\n",
    "print(elu_net)\n",
    "print(elu_net(torch.ones(3, 3, 24, 24)).shape)\n",
    "\n",
    "# 3D network instance with anisotropic kernels\n",
    "sigmoid_net = MyNetwork(3, in_channels=4, kernel_size=(3, 3, 1), act=\"sigmoid\")\n",
    "print(sigmoid_net)\n",
    "print(sigmoid_net(torch.ones(3, 4, 30, 30, 5)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-adobe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MONAI Networks\n",
    "\n",
    "MONAI provides over 20 Networks including:\n",
    "- UNet\n",
    "- VNet\n",
    "- AHNet\n",
    "- VGG-like regressor, classifier, discriminator, critic\n",
    "- HighResNet\n",
    "- SENet\n",
    "- UNETR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-architecture",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example UNets\n",
    "\n",
    "We'll define a 2D UNet network with 2 hidden layers having outputs with 8 channels, and a bottom (bottleneck) layer producing outputs with 32 channels.  The stride values state the stride for the initial convolution, ie. downsampling in down path and upsampling in up path and it'll transpose the convolutions used to implement upsampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-morocco",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net = monai.networks.nets.UNet(\n",
    "    spatial_dims=2,  # 2 or 3 for a 2D or 3D network\n",
    "    in_channels=1,  # number of input channels\n",
    "    out_channels=1,  # number of output channels\n",
    "    channels=[8, 16, 32],  # channel counts for layers\n",
    "    strides=[2, 2]  # strides for mid layers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-wedding",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "We've covered MONAI Transforms, Datasets, Caching and Networks.  Some key highlights are:\n",
    "\n",
    "- There is a long list of medical specific transforms available in MONAI\n",
    "- There are array and dictionary versions of transforms.\n",
    "- You can create a simple callable lambda function or create a class based on transform to create your own custom tranform\n",
    "- You can create a MONAI dataset and directly pass a compose tranform chain to it\n",
    "- A MONAI Dataset is a generic dataset with a len property, getitem property, and an optional callable data transform when fetching a data sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba2d4b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "- You can use dataset caching to store dataset transforms to speed up training.  Some included Caching options are CachingDataset, PersistentCaching, and SmartCaching\n",
    "- MONAI provides access to some commonly used medical imaging datasets including the DecathlonDataset\n",
    "- Understanding the basic MONAI Layers, Blocks, and Networks\n",
    "- Use MONAI layers to implement a flexible network and instnaite a two UNet examples with different parameters"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "rise": {
   "header": "<img style='width: 100%; height: 100%;' src='https://raw.githubusercontent.com/Project-MONAI/project-monai.github.io/master/assets/logo/MONAI-logo_color.svg'>",
   "scroll": true,
   "theme": "white"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
